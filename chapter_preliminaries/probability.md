```{.python .input}
%load_ext d2lbook.tab
tab.interact_select(['mxnet', 'pytorch', 'tensorflow'])
```

# 確率と統計
:label:`sec_prob`

いずれにせよ、機械学習は不確実性に関するものです。教師あり学習では、既知のもの（*特徴*）から未知のもの（*ターゲット*）を予測したいと考えています。目的に応じて、ターゲットの最も可能性の高い値を予測しようとするかもしれません。または、ターゲットから予想される最小距離で値を予測することもできます。また、特定の値を予測するだけでなく、*不確実性を定量化*したい場合もあります。たとえば、患者を説明するいくつかの特徴を考えると、来年に心臓発作を起こす可能性が*どの程度*あるかを知りたい場合があります。教師なし学習では、私たちはしばしば不確実性を気にします。一連の測定値が異常であるかどうかを判断するには、対象の母集団の値を観測する可能性がどの程度あるかを知ることが役立ちます。また、強化学習では、さまざまな環境でインテリジェントに作用するエージェントを開発したいと考えています。これには、環境がどのように変化すると予想されるか、利用可能な各アクションに応じてどのような報酬が発生すると予想されるかについての推論が必要です。 

*確率* は数学的なフィールドです
不確実性の下での推論に関心がある。あるプロセスの確率モデルを考えると、さまざまなイベントの可能性について推論できます。繰り返し可能なイベント（コイントスのような）の頻度を記述するために確率を使用することは、かなり議論の余地がありません。実際、*頻度論者*の学者は、そのような反復可能な出来事に*のみ*当てはまる確率の解釈に固執しています。対照的に、*ベイジアン*の学者は、不確実性の下での推論を形式化するために、確率の言語をより広く使用します。ベイズ確率は、2つのユニークな特徴によって特徴付けられます。（i）反復不可能な出来事に信念度を割り当てる、例えば、月がチーズでできているという*確率*はどれくらいですか？; と（ii）主観性—ベイズ確率は、新しい証拠に照らして信念をどのように更新すべきかについての明確なルールを提供しますが、異なる個人が異なる*以前の*信念から始めることを可能にします。
*統計*は、私たちが逆に推論するのに役立ちます。
データの収集と整理から始めて、データを生成したプロセスについてどのような推論を引き出すかを取り戻します。データセットを分析し、より広範な人口を特徴付ける可能性のあるパターンを探すときはいつでも、統計的思考を採用しています。ほとんどのコース、専攻、論文、キャリア、学科、企業、教育機関は、確率と統計の研究に専念してきました。このセクションは表面を傷つけるだけですが、モデルの構築を開始するために必要な基礎を提供します。 

## 簡単な例:コインを投げる

コインを投げる予定で、頭（対尾）が見える可能性を定量化したいと想像してみてください。コインが*公平*であれば、両方の結果（ヘッドとテール）は等しくありそうです。さらに、コインを$n$回投げることを計画している場合、私たちが*期待*する*頭の割合は、*予想される*テールの割合と正確に一致するはずです。これを直感的に確認する方法の1つは対称性です。$n_h$の頭と$n_t = (n - n_h)$の尾を持つ可能性のあるすべての結果について、$n_t$の頭と$n_h$の尾で同じ可能性の高い結果があります。これが可能なのは、平均して$1/2$のトスが頭上に上がり、$1/2$が尾を上がると予想される場合にのみ可能であることに注意してください。もちろん、$n=1000000$をそれぞれ投げてこの実験を何度も行った場合、$n_h = n_t$が正確に試行されることは決してないかもしれません。 

正式には、$1/2$という量は*確率*と呼ばれ、ここでは、与えられたトスが頭に浮かぶ確実性を捉えています。確率は、*事象*と呼ばれる関心のある結果に$0$から$1$の間のスコアを割り当てます。ここで、関心のある事象は$\textrm{heads}$であり、対応する確率$P(\textrm{heads})$を示します。$1$の確率は絶対確実性を示し（両側が頭だったトリックコインを想像してみてください）、$0$の確率は不可能であることを示します（たとえば、両側が尾である場合）。周波数$n_h/n$と$n_t/n$は確率ではなく、むしろ*統計*です。確率は、データ生成プロセスの基礎となる「理論的」な量です。ここで、確率$1/2$はコイン自体の特性です。対照的に、統計は、観測データの関数として計算される「経験的」な量です。確率的および統計的量に対する私たちの関心は、密接に絡み合っています。私たちはしばしば、データセットが与えられると、確率などのモデルパラメータの*推定*を生成する、*推定器*と呼ばれる特別な統計を設計します。さらに、これらの推定器が*一貫性*と呼ばれる優れた特性を満たす場合、推定値は対応する確率に収束します。次に、これらの推定された確率は、将来遭遇する可能性のある、同じ母集団からのデータの統計的特性について示しています。 

本当の$P(\textrm{heads})$を知らなかった本物のコインに出くわしたとします。この量を統計的手法で調べるには、(i) いくつかのデータを収集し、(ii) 推定量を設計する必要があります。ここでのデータ取得は簡単です。コインを何度も投げて、すべての結果を記録できます。正式には、基礎となるランダムプロセスから実現を引き出すことを*サンプリング*と呼びます。ご想像のとおり、自然推定量の1つは、観察された*頭*の数と投げの総数の間の割合です。

```{.python .input}
%%tab mxnet
%matplotlib inline
from d2l import mxnet as d2l
from mxnet import np, npx
from mxnet.numpy.random import multinomial
import random
npx.set_np()
```

```{.python .input}
%%tab pytorch
%matplotlib inline
from d2l import torch as d2l
import random
import torch
from torch.distributions.multinomial import Multinomial
```

```{.python .input}
%%tab tensorflow
%matplotlib inline
from d2l import tensorflow as d2l
import random
import tensorflow as tf
from tensorflow_probability import distributions as tfd
```

ここで、コインが実際に公正だったと仮定します。つまり、$P(\textrm{heads}) = 0.5$。公正なコインの投げをシミュレートするために、任意の乱数ジェネレータを呼び出すことができます。確率$0.5$で事象のサンプルを抽出する簡単な方法。たとえば、Pythonの`random.random`は、$[0,1]$の間隔の数値を生成します。ここで、サブインターバル$[a, b] \subset [0,1]$にある確率は、$b-a$に等しくなります。したがって、返された浮動小数点数が`0.5`より大きいかどうかをテストすることにより、`0`と`1`をそれぞれ確率`0.5`で取得できます。

```{.python .input}
%%tab all
num_tosses = 100
heads = sum([random.random() > 0.5 for _ in range(100)])
tails = num_tosses - heads
print("heads, tails: ", [heads, tails])
```

より一般的には、多項関数を呼び出し、最初の引数をドローの数に設定し、2番目の引数をそれぞれに関連付けられた確率のリストとして設定することにより、有限数の可能な結果（コインの投げやサイコロのロールなど）を持つ任意の変数からの複数のドローをシミュレートできます。可能な結果。公正なコインを10回投げることをシミュレートするために、確率ベクトル`[0.5, 0.5]`を割り当て、インデックス0をヘッド、インデックス1をテールと解釈します。この関数は、可能な結果の数 (ここでは 2) に等しい長さのベクトルを返します。最初の成分は頭部の出現回数を示し、2 番目の成分は尾の発生数を示します。

```{.python .input}
%%tab mxnet
fair_probs = [0.5, 0.5]
multinomial(100, fair_probs)
```

```{.python .input}
%%tab pytorch
fair_probs = torch.tensor([0.5, 0.5])
Multinomial(100, fair_probs).sample()
```

```{.python .input}
%%tab tensorflow
fair_probs = tf.ones(2) / 2
tfd.Multinomial(100, fair_probs).sample()
```

このサンプリングプロセスを実行するたびに、前の結果とは異なる可能性のある新しい乱数値が得られます。投げる回数で割ると、データに含まれる各結果の*頻度*がわかります。これらの周波数は、推定する確率と同様に、合計が$1$になることに注意してください。

```{.python .input}
%%tab mxnet
multinomial(100, fair_probs) / 100
```

```{.python .input}
%%tab pytorch
Multinomial(100, fair_probs).sample() / 100
```

```{.python .input}
%%tab tensorflow
tfd.Multinomial(100, fair_probs).sample() / 100
```

ここでは、シミュレートしたコインが公平であっても（確率`[0.5, 0.5]`を自分たちで設定しました）、頭と尾のカウントは同一ではないかもしれません。これは、有限数のサンプルしか描画しなかったからです。シミュレーションを自分たちで実装せず、結果だけを見た場合、コインが少し不公平なのか、$1/2$からの逸脱の可能性がサンプルサイズの小さいアーティファクトだったのかをどうやって知ることができますか？`10000`の投げをシミュレートするとどうなるか見てみましょう。

```{.python .input}
%%tab mxnet
counts = multinomial(10000, fair_probs).astype(np.float32)
counts / 10000
```

```{.python .input}
%%tab pytorch
counts = Multinomial(10000, fair_probs).sample()
counts / 10000
```

```{.python .input}
%%tab tensorflow
counts = tfd.Multinomial(10000, fair_probs).sample()
counts / 10000
```

一般に、繰り返されるイベント（コイントスのような）の平均では、繰り返し数が増えるにつれて、推定値は真の基礎となる確率に収束することが保証されます。この現象の数学的証明は*大数の法則*と呼ばれ、*中心極限定理*は、多くの状況で、サンプルサイズ$n$が大きくなるにつれて、これらの誤差は$(1/\sqrt{n})$の割合で減少するはずであることを示しています。投げの数を`1`から`10000`に増やすにつれて、見積もりがどのように進化するかを調べて、もう少し直感的になりましょう。

```{.python .input}
%%tab mxnet
counts = multinomial(1, fair_probs, size=10000)
cum_counts = counts.astype(np.float32).cumsum(axis=0)
estimates = cum_counts / cum_counts.sum(axis=1, keepdims=True)
```

```{.python .input}
%%tab pytorch
counts = Multinomial(1, fair_probs).sample((10000,))
cum_counts = counts.cumsum(dim=0)
estimates = cum_counts / cum_counts.sum(dim=1, keepdims=True)
estimates = estimates.numpy()
```

```{.python .input}
%%tab tensorflow
counts = tfd.Multinomial(1, fair_probs).sample(10000)
cum_counts = tf.cumsum(counts, axis=0)
estimates = cum_counts / tf.reduce_sum(cum_counts, axis=1, keepdims=True)
estimates = estimates.numpy()
```

```{.python .input}
%%tab all
d2l.set_figsize((4.5, 3.5))
d2l.plt.plot(estimates[:, 0], label=("P(coin=heads)"))
d2l.plt.plot(estimates[:, 1], label=("P(coin=tails)"))
d2l.plt.axhline(y=0.5, color='black', linestyle='dashed')
d2l.plt.gca().set_xlabel('Samples')
d2l.plt.gca().set_ylabel('Estimated probability')
d2l.plt.legend();
```

各実線曲線は、コインの2つの値のうちの1つに対応し、実験の各グループの後にコインがその値を上げると推定される確率を示します。黒い破線は、真の基礎確率を示しています。より多くの実験を行うことでより多くのデータを取得すると、曲線は真の確率に向かって収束します。統計学者を悩ませる、より高度な質問の形をすでに理解し始めているかもしれません。この収束はどれくらい早く起こるのですか？同じ工場で製造された多くのコインをすでにテストした場合、この情報をどのように組み込むことができるでしょうか？ 

##  よりフォーマルな扱い

確率的モデルの提案、合成データの生成、統計的推定の実行、収束の経験的評価、エラーメトリクスの報告（偏差のチェック）など、すでにかなり遠くまで進んでいます。しかし、さらに先に進むには、より正確にする必要があります。 

ランダム性を扱う場合、可能な結果の集合を$\mathcal{S}$と表し、それを*サンプル空間*または*結果空間*と呼びます。ここで、各要素は異なる可能性のある*結果*です。単一のコインを転がす場合、$\mathcal{S} = \{\textrm{heads}, \textrm{tails}\}$。単一のダイの場合、$\mathcal{S} = \{1, 2, 3, 4, 5, 6\}$。2つのコインをひっくり返すと、4つの結果が考えられます：$\{(\textrm{heads}, \textrm{heads}), (\textrm{heads}, \textrm{tails}), (\textrm{tails}, \textrm{heads}),  (\textrm{tails}, \textrm{tails})\}$。
*イベント* はサンプル空間のサブセットです。
たとえば、「最初のコイントスが頭を上げる」というイベントは、セット$\{(\textrm{heads}, \textrm{heads}), (\textrm{heads}, \textrm{tails})\}$に対応します。ランダム実験の結果 $z$ が $z \in \mathcal{A}$ を満たすたびに、事象 $\mathcal{A}$ が発生しています。サイコロを1回振ると、「$5$を見る」（$\mathcal{A} = \{5\}$）と「奇数を見る」（$\mathcal{B} = \{1, 3, 5\}$）というイベントを定義できます。この場合、ダイが`5`になった場合、$A$と$B$の両方が発生したと言えます。一方、$z = 3$の場合、$\mathcal{A}$は発生しませんでしたが、$\mathcal{B}$は発生しました。 

*確率* 関数は、イベントを実数値 ${P: \mathcal{A} \subseteq \mathcal{S} \rightarrow [0,1]}$ にマッピングします。$P(\mathcal{A})$と示される、指定されたサンプル空間$\mathcal{S}$における事象$\mathcal{A}$の確率は、次の特性を満たします。 

* 任意の事象の確率$\mathcal{A}$は非負の実数、すなわち$P(\mathcal{A}) \geq 0$です。
* サンプル空間全体の確率は$1$、つまり$P(\mathcal{S}) = 1$です。
* *相互に排他的*（$\mathcal{A}_i \cap \mathcal{A}_j = \emptyset$、$i \neq j$）の可算イベントシーケンス $\mathcal{A}_1, \mathcal{A}_2, \ldots$ の場合、それらのいずれかが発生する確率は、個々の確率の合計、つまり $P(\bigcup_{i=1}^{\infty} \mathcal{A}_i) = \sum_{i=1}^{\infty} P(\mathcal{A}_i)$ と等しくなります。

:citet:`Kolmogorov.1933`によって提案されたこれらの確率論の公理は、多くの重要な結果を迅速に導き出すために適用することができます。たとえば、任意の事象の確率は$\mathcal{A}$とすぐにわかります
*または* その補数 $\mathcal{A}'$ の発生は 1 です
(なぜなら$\mathcal{A} \cup \mathcal{A}' = \mathcal{S}$)。$P(\emptyset) = 0$は、$1 = P(\mathcal{S} \cup \mathcal{S}') = P(\mathcal{S} \cup \emptyset) = P(\mathcal{S}) + P(\emptyset) = 1 + P(\emptyset)$であるため、それを証明することもできます。その結果、いずれかの事象の確率$\mathcal{A}$
*と* その補数 $\mathcal{A}'$ が同時に発生する
は$P(\mathcal{A} \cap \mathcal{A}') = 0$です。非公式に、これは不可能なイベントが発生する可能性がゼロであることを示しています。 

## ランダム変数

ダイスのロールが来るオッズや最初のコイントスのような出来事について話したとき、私たちは*ランダム変数*のアイデアを呼び起こしていました。正式には、確率変数は、基礎となるサンプル空間から一連の (場合によっては多数の) 値へのマッピングです。確率変数はサンプル空間とどう違うのか不思議に思うかもしれません。どちらも結果の集まりだからです。重要なのは、確率変数は生のサンプル空間よりもはるかに粗い場合があることです。基礎となるサンプル空間が無限大の場合でも、「0.5より大きい」などのバイナリ確率変数を定義できます。たとえば、$0$と$1$の間の線分などです。さらに、複数の確率変数が同じ基礎となるサンプル空間を共有できます。たとえば、「自宅のアラームが鳴るかどうか」と「自宅が盗難に遭ったかどうか」は、基礎となるサンプル空間を共有するバイナリ確率変数です。したがって、ある確率変数がとる値を知ることで、別の確率変数の可能性のある値について何かを知ることができます。警報が鳴ったことを知っていると、その家が強盗されたのではないかと疑うかもしれません。 

確率変数によって取られるすべての値は、基礎となるサンプル空間のサブセットに対応します。したがって、$X=v$によって示される確率変数$X$が値$v$をとるオカレンスは*事象*であり、$P(X=v)$はその確率を示します。この表記法が不格好になることもあり、文脈が明確な場合は記法を乱用する可能性があります。たとえば、$P(X)$を使用して、$X$の*分布*、つまり、$X$が任意の値をとる確率を示す関数を広く参照できます。また、$P(X,Y) = P(X) P(Y)$のような式を、確率変数$X$と$Y$が取ることができるすべての値に当てはまるステートメントを表現するための省略形として、つまり、すべての$i,j$に対してその$P(X=i \textrm{ and } Y=j) = P(X=i)P(Y=j)$を保持します。また、確率変数が文脈から明らかな場合、$P(v)$と書くことで表記法を乱用することもあります。確率論における事象はサンプル空間からの結果の集合であるため、確率変数が取る値の範囲を指定できます。たとえば、$P(1 \leq X \leq 3)$ は事象 $\{1 \leq X \leq 3\}$ の確率を示します。 

コインのフリップやサイコロの投げなどの*離散*確率変数と、人口から無作為にサンプリングされた人の体重や身長などの*連続*の確率変数には微妙な違いがあることに注意してください。この場合、私たちは誰かの正確な身長を本当に気にすることはめったにありません。さらに、十分に正確に測定すると、地球上でまったく同じ高さの人は2人いないことがわかります。実際、十分に細かい測定値があれば、目覚めたときと寝るときと同じ高さになることは決してありません。身長が1.801392782910287192メートルである正確な確率について尋ねる意味はほとんどありません。代わりに、私たちは通常、誰かの身長が特定の間隔、たとえば1.79メートルから1.81メートルの間にあるかどうかを言うことができることを重視しています。これらのケースでは、確率*密度*を使って作業します。正確に1.80メートルの高さには確率はありませんが、密度はゼロではありません。区間に割り当てられた確率を出すには、その区間の密度の*積分*を取らなければなりません。 

## 複数のランダム変数

複数の確率変数間の相互作用を含むステートメントを作成しないと、最後のセクションを通過することすらできないことに気づいたかもしれません（$P(X,Y) = P(X) P(Y)$を思い出してください）。機械学習のほとんどは、そのような関係に関係しています。ここで、サンプルスペースは、関心のある集団、たとえば企業と取引する顧客、インターネット上の写真、または生物学者に知られているタンパク質です。各確率変数は、異なる属性の（未知の）値を表します。母集団から個体をサンプリングするたびに、各確率変数の実現が観察されます。確率変数によって取られる値は、重なり合っている、部分的に重なっている、または完全に切り離されている可能性があるサンプル空間のサブセットに対応するため、ある確率変数が取る値を知ることで、別の確率変数のどの値になり得るかについての信念を更新することができます。患者が病院に入院し、呼吸困難で嗅覚が失われているのを観察した場合、呼吸障害がなく、完全に普通の嗅覚がない場合よりも、COVID-19に感染する可能性が高いと私たちは信じています。 

複数の確率変数を扱う場合、変数が一緒に取ることができる値のあらゆる組み合わせに対応するイベントを構築できます。これらの組み合わせのそれぞれに確率を割り当てる確率関数 (例:$A=a$ と $B=b$) は、*結合確率* 関数と呼ばれ、サンプル空間の対応するサブセットの交差に割り当てられた確率を単純に返します。確率変数$A$と$B$がそれぞれ$a$と$b$の値を取る事象に割り当てられた*結合確率*は、$P(A = a, B = b)$と表され、カンマは「and」を示します。$a$ と $b$ のいずれかの値については、$P(A=a, B=b) \leq P(A=a)$ と $P(A=a, B=b) \leq P(B = b)$ が保持されることに注意してください。$A=a$ と $B=b$ が発生するには、$A=a$ が発生する必要があるため、* $B=b$ も発生する必要があります。興味深いことに、結合確率は、確率的な意味でこれらの確率変数について知ることができ、個々の分布$P(A)$および$P(B)$の回復を含む、他の多くの有用な量を導出するために使用できることをすべて教えてくれます。$P(A=a)$ を回復するには、ランダム変数 $B$ が取ることができるすべての値 $v$ に対して $P(A=a, B=v)$ を単純に合計します。$P(A=a) = \sum_v P(A=a, B=v)$。 

$\frac{P(A=a, B=b)}{P(A=a)} \leq 1$の比率は非常に重要であることがわかりました。これは*条件付き確率*と呼ばれ、「$\mid$」記号$P(B=b \mid A=a) = P(A=a,B=b)/P(A=a)$によって示されます。これは、$A=a$が発生したという事実を条件付けると、イベント$B=b$に関連する新しい確率を示します。この条件付き確率は、$A=a$ に関連付けられたサンプル空間のサブセットのみに注意を制限し、すべての確率の合計が 1 になるように再正規化すると考えることができます。条件付き確率は実際には確率であり、すべての項を同じ事象に条件付けして同じサンプル空間に注意を制限する限り、すべての公理を尊重します。たとえば、切り離されたイベント $\mathcal{B}$ と $\mathcal{B}'$ の場合、その $P(\mathcal{B} \cup \mathcal{B}' \mid A = a) = P(\mathcal{B} \mid A = a) + P(\mathcal{B}' \mid A = a)$ があります。 

条件付き確率の定義を使用して、*ベイズの定理*と呼ばれる有名な結果を導き出すことができます。構造上、$P(A, B) = P(B\mid A) P(A)$と$P(A, B) = P(A\mid B) P(B)$があります。両方の方程式を組み合わせると $P(B\mid A) P(A) = P(A\mid B) P(B)$ が得られ、したがって 

$$P(A \mid B) = \frac{P(B\mid A) P(A)}{P(B)}.$$

この単純な方程式は、条件付けの順序を逆にすることができるため、深い意味を持ちます。$P(B\mid A)$、$P(A)$、$P(B)$を推定する方法がわかっている場合は、$P(A\mid B)$を推定できます。私たちはしばしば、一方の項を直接推定するが、他の項は推定しない方が簡単であり、ベイズの定理がここで助けになります。たとえば、特定の疾患の症状の有病率と、その疾患と症状の全体的な有病率をそれぞれ知っていれば、その症状に基づいてその病気にかかる可能性を判断できます。場合によっては、症状の有病率など、$P(B)$に直接アクセスできない場合があります。この場合、ベイズの定理の簡略版が役に立ちます。 

$$P(A \mid B) \propto P(B \mid A) P(A).$$

$P(A \mid B)$は$1$、つまり$\sum_a P(A=a \mid B) = 1$に正規化する必要があることがわかっているので、これを使用して計算できます 

$$P(A \mid B) = \frac{P(B \mid A) P(A)}{\sum_b P(B=b \mid A) P(A)}.$$

ベイズ統計では、オブザーバーは、*事前* $P(H)$にエンコードされた利用可能な仮説の妥当性についての（主観的な）事前信念と、各仮説について収集された証拠の価値を観察する可能性がどの程度あるかを示す*尤度関数*を持っていると考えていますクラス$P(E \mid H)$。ベイズの定理は、*事後*信念$P(H \mid E) = \frac{P(E \mid H) P(H)}{P(E)}$を生成するために入手可能な証拠$E$に照らして、最初の*前の* $P(H)$を更新する方法を教えてくれると解釈されます。非公式には、これは「事後は前の時間の尤度を証拠で割った値と等しい」と表現できます。さて、証拠$P(E)$はすべての仮説で同じであるため、仮説を単純に正規化することで回避できます。 

$\sum_a P(A=a \mid B) = 1$では、確率変数に対して*疎外*することもできることに注意してください。つまり、$P(A, B)$ などの共同分布から変数を削除できます。結局のところ、私たちはそれを持っています 

$$\sum_a P(A=a, B) = P(B) \sum_a P(A = a \mid B) = P(B).$$

独立性は、統計学における多くの重要なアイデアのバックボーンを形成するもう1つの根本的に重要な概念です。つまり、$A$の値を条件付けても、$B$に関連する確率分布に変化が生じない場合、またはその逆の場合、2つの変数は*独立*です。より正式には、$A \perp B$と示される独立性には、$P(A \mid B) = P(A)$が必要であり、その結果、$P(A,B) = P(A \mid B) P(B) = P(A) P(B)$が必要です。独立性はしばしば適切な仮定です。たとえば、確率変数$A$が1つの公正なコインを投げた結果を表し、確率変数$B$が別のコインを投げた結果を表す場合、$A$が上向きになったかどうかを知ることは、$B$が上向きになる確率に影響しないはずです。 

独立性は、基礎となる分布からデータを連続的に引き出す場合（強力な統計的結論を出すことができる）、またはデータ内のさまざまな変数に保持され、この独立構造をエンコードするより単純なモデルで作業できるようにする場合に特に役立ちます。一方、確率変数間の依存関係を推定することは、多くの場合、学習のまさに目的です。私たちは、病気と症状が*独立していない*と考えているため、特に症状が与えられた疾患の確率を推定することに気を配っています。 

条件付き確率は適切な確率であるため、独立性と依存性の概念もそれらに適用されることに注意してください。2つの確率変数$A$と$B$は、$P(A, B \mid C) = P(A \mid C)P(B \mid C)$の場合に限り、3番目の変数$C$が与えられると、*条件付きで独立*されます。興味深いことに、2つの変数は一般的に独立している可能性がありますが、3つ目の変数に条件付けを行うと従属します。これは、2つの確率変数$A$と$B$が第3の変数$C$の原因に対応する場合によく発生します。例えば、骨折や肺がんは一般集団では独立しているかもしれませんが、入院を条件付ければ、骨折は肺がんと負の相関があることがわかるかもしれません。それは、骨折がなぜ入院しているのかを「説明する」ため、肺がんになる可能性が低くなるからです。 

逆に、2 つの従属確率変数は、3 つ目の条件付けによって独立になります。これは、関連性のない 2 つのイベントに共通の原因がある場合によく発生します。靴のサイズと読解レベルは小学生の間で高い相関があるが、年齢を条件付ければこの相関関係はなくなる。 

## 一例
:label:`subsec_probability_hiv_app`

私たちのスキルを試そう。医師が患者にHIV検査を行うと仮定します。この検査はかなり正確であり、患者が健康であるが病気であると報告している場合、1％の確率で失敗するだけです。さらに、患者が実際にHIVに感染していれば、HIVの検出に失敗することはありません。診断を示すために$D_1 \in \{0, 1\}$（陰性の場合は$0$、陽性の場合は$1$）、HIVの状態を示すために$H \in \{0, 1\}$を使用します。 

| Conditional probability | $H=1$ | $H=0$ |
|:------------------------|------:|------:|
| $P(D_1 = 1 \mid H)$        |     1 |  0.01 |
| $P(D_1 = 0 \mid H)$        |     0 |  0.99 |

列の合計は条件付き確率であるため、すべて1です（ただし、行の合計はそうではありません）。検査が陽性になった場合、患者がHIVに感染する確率、つまり$P(H = 1 \mid D_1 = 1)$を計算してみましょう。直感的には、これは誤報の数に影響を与えるため、病気がどれほど一般的であるかに依存します。人口がかなり健全であると仮定します (例:$P(H=1) = 0.0015$)。ベイズの定理を適用するには、疎外化を適用して決定する必要があります 

$$\begin{aligned}
P(D_1 = 1)
=& P(D_1=1, H=0) + P(D_1=1, H=1)  \\
=& P(D_1=1 \mid H=0) P(H=0) + P(D_1=1 \mid H=1) P(H=1) \\
=& 0.011485.
\end{aligned}
$$

これは私たちを導きます 

$$P(H = 1 \mid D_1 = 1) = \frac{P(D_1=1 \mid H=1) P(H=1)}{P(D_1=1)} = 0.1306.$$

言い換えれば、非常に正確な検査を使用しているにもかかわらず、患者が実際にHIVに感染する可能性は13.06％しかありません。ご覧のとおり、確率は直観に反する可能性があります。そのような恐ろしい知らせを受けたとき、患者は何をすべきか？おそらく、患者は明確にするために別の検査を行うように医師に依頼するでしょう。2番目のテストにはさまざまな特性があり、最初のテストほど良くありません。 

| Conditional probability | $H=1$ | $H=0$ |
|:------------------------|------:|------:|
| $P(D_2 = 1 \mid H)$          |  0.98 |  0.03 |
| $P(D_2 = 0 \mid H)$          |  0.02 |  0.97 |

残念ながら、2番目のテストも陽性に戻ります。条件付き独立性を仮定して、ベイズの定理を呼び出すために必要な確率を計算しましょう。 

$$\begin{aligned}
P(D_1 = 1, D_2 = 1 \mid H = 0)
& = P(D_1 = 1 \mid H = 0) P(D_2 = 1 \mid H = 0)
=& 0.0003, \\
P(D_1 = 1, D_2 = 1 \mid H = 1)
& = P(D_1 = 1 \mid H = 1) P(D_2 = 1 \mid H = 1)
=& 0.98.
\end{aligned}
$$

これで、疎外化を適用して、両方のテストが陽性になる確率を得ることができます。 

$$\begin{aligned}
P(D_1 = 1, D_2 = 1)
=& P(D_1 = 1, D_2 = 1, H = 0) + P(D_1 = 1, D_2 = 1, H = 1)  \\
=& P(D_1 = 1, D_2 = 1 \mid H = 0)P(H=0) + P(D_1 = 1, D_2 = 1 \mid H = 1)P(H=1)\\
=& 0.00176955.
\end{aligned}
$$

最後に、両方の検査で患者がHIVに感染する確率は陽性です 

$$P(H = 1 \mid D_1 = 1, D_2 = 1)
= \frac{P(D_1 = 1, D_2 = 1 \mid H=1) P(H=1)}{P(D_1 = 1, D_2 = 1)}
= 0.8307.$$

つまり、2回目のテストでは、すべてが順調ではないという確信がはるかに高まりました。2番目のテストは最初のテストよりもかなり正確ではありませんが、それでも見積もりは大幅に改善されました。両方のテストが互いに独立した条件付きであるという仮定は、より正確な推定値を生成する能力にとって重要でした。同じテストを2回実行する極端なケースを考えてみましょう。この状況では、両方の時間で同じ結果が期待されるため、同じテストを再度実行しても追加の洞察は得られません。賢明な読者は、診断が明白な視界に隠れている分類器のように振る舞い、より多くの特徴（検査結果）が得られるにつれて患者が健康であるかどうかを判断する能力が高まることに気付いたかもしれません。 

## 期待

多くの場合、意思決定を行うには、個々のイベントに割り当てられた確率を見るだけでなく、ガイダンスを提供できる有用な集計にまとめる必要があります。たとえば、確率変数が連続スカラー値をとる場合、*平均*で期待される値を知ることがしばしば気になります。この量は、正式には*期待値*と呼ばれます。私たちが投資を行っている場合、最初の関心の量は、すべての可能な結果を平均して（そして適切な確率で重み付けして）期待できるリターンかもしれません。たとえば、50% の確率で投資が完全に失敗する可能性があり、40% の確率で2$\times$のリターンが得られ、10% の確率で10$\times$のリターンが10$\times$になる可能性があるとします。期待リターンを計算するには、すべてのリターンを合計し、それぞれにリターンの発生確率を掛けます。これにより、$0.5 \cdot 0 + 0.4 \cdot 2 + 0.1 \cdot 10 = 1.8$ という期待値が得られます。したがって、期待されるリターンは1.8$\times$です。 

一般に、確率変数$X$の*期待値*（または平均）は次のように定義されます。 

$$E[X] = E_{x \sim P}[x] = \sum_{x} x P(X = x).$$

同様に、密度については $E[X] = \int x \;dp(x)$ を取得します。時々、$x$のいくつかの関数の期待値に興味があります。これらの期待値は次のように計算できます。 

$$E_{x \sim P}[f(x)] = \sum_x f(x) P(x) \text{ and } E_{x \sim P}[f(x)] = \int f(x) p(x) \;dx$$

離散確率と密度のそれぞれについて。上記の投資例に戻ると、$f$はリターンに関連する*効用*（幸福）かもしれません。行動経済学者は長い間、人々はベースラインと比較して1ドルを稼ぐことから得られる効用よりも大きな不実用性とお金の損失を関連付けることに注目してきました。さらに、お金の価値はサブリニアになる傾向があります。ゼロドルに対して10万ドルを所有することは、家賃を払うこと、よく食べること、そして質の高い医療を楽しむこととホームレスを通して苦しむことの違いを生むことができます。一方、100kに対して200kを所有することによる利益はそれほど劇的ではありません。このような推論は、「お金の効用は対数的である」という決まり文句の動機付けになります。 

総損失に関連するユーティリティが-1で、リターン1、2、および10に関連するユーティリティがそれぞれ1、2、4である場合、投資の期待幸福度は$0.5 \cdot (-1) + 0.4 \cdot 2 + 0.1 \cdot 4 = 0.7$（期待されるユーティリティの損失 30%）になります。本当にこれがあなたのユーティリティ機能だったら、お金を銀行に保管するのが最善かもしれません。 

財務上の決定については、投資がどの程度*リスクが高い*かを測定したい場合もあります。ここでは、期待値だけでなく、実際の値がこの値に対してどの程度*変化*する傾向があるかを考慮します。実際の値と期待される値の差を単に期待することはできないことに注意してください。これは、違いの期待が期待値の差であり、$E[X - E[X]] = E[X] - E[E[X]] = 0$だからです。しかし、この差の非負の関数の期待を見ることができます。確率変数の*分散*は、*二乗*偏差の期待値を調べることによって計算されます。 

$$\mathrm{Var}[X] = E\left[(X - E[X])^2\right] = E[X^2] - E[X]^2.$$

ここでは、$(X - E[X])^2 = X^2 - 2 X E[X] + E[X]^2$を拡張し、各学期に期待を出すことで平等が続きます。分散の平方根は、*標準偏差*と呼ばれる別の有用な量です。分散と標準偏差は同じ情報を伝達しますが（どちらも他方から計算できます）、標準偏差には、確率変数で表される元の量と同じ単位で表されるという優れた特性があります。 

最後に、確率変数の関数の分散は次のように定義されます。 

$$\mathrm{Var}_{x \sim P}[f(x)] = E_{x \sim P}[f^2(x)] - E_{x \sim P}[f(x)]^2.$$

投資の例に戻ると、投資の分散を計算できます。これは $0.5 \cdot 0 + 0.4 \cdot 2^2 + 0.1 \cdot 10^2 - 1.8^2 = 8.36$ によって与えられます。すべての意図と目的に対して、これはリスクの高い投資です。数学的な慣習では、平均と分散は$\mu$と$\sigma^2$として参照されることがよくあります。これは、ガウス分布をパラメータ化するために使用する場合は常に特に一般的です。 

*スカラー* 確率変数に期待値と分散を導入したのと同じように、ベクトル値の確率変数についてもそうすることができます。要素ごとに適用できるので、期待は簡単です。たとえば、$\boldsymbol{\mu} \stackrel{\mathrm{def}}{=} E_{\mathbf{x} \sim P}[\mathbf{x}]$ の座標は $\mu_i = E_{\mathbf{x} \sim P}[x_i]$ です。共分散はもっと複雑です。この問題を解決するには、確率変数とその平均の差の*外積*を期待します。 

$$\boldsymbol{\Sigma} \stackrel{\mathrm{def}}{=} \mathrm{Cov}_{\mathbf{x} \sim P}[\mathbf{x}] = E_{\mathbf{x} \sim P}\left[(\mathbf{x} - \boldsymbol{\mu}) (\mathbf{x} - \boldsymbol{\mu})^\top\right].$$

この行列 $\boldsymbol{\Sigma}$ は、共分散行列と呼ばれます。その効果を確認する簡単な方法は、$\mathbf{x}$ と同じサイズのベクトル $\mathbf{v}$ を検討することです。それに従う 

$$\mathbf{v}^\top \boldsymbol{\Sigma} \mathbf{v} = E_{\mathbf{x} \sim P}\left[\mathbf{v}^\top(\mathbf{x} - \boldsymbol{\mu}) (\mathbf{x} - \boldsymbol{\mu})^\top \mathbf{v}\right] = \mathrm{Var}_{x \sim P}[\mathbf{v}^\top \mathbf{x}].$$

そのため、$\boldsymbol{\Sigma}$では、$\mathbf{x}$の任意の線形関数の分散を単純な行列乗算で計算できます。非対角要素は、座標がどの程度相関しているかを示します。値0は相関がないことを意味し、正の値が大きいほど相関が強いことを意味します。 

## ディスカッション

機械学習には、不確かなことがたくさんあります！入力されたラベルの値については不確かな場合があります。パラメータの推定値については不確かな場合があります。展開時に到着するデータがトレーニングデータと同じ分布からのものであるかどうかさえ不確かになることもあります。 

*偶然性の不確実性*によって、問題に内在する不確実性、および観測された変数によって説明されない真のランダム性による不確実性を示します。*認識論的不確実性*とは、モデルのパラメータに対する不確実性を表します。これは、より多くのデータを収集することで削減できると期待できる種類の不確実性です。コインが頭を上げる確率に関して認識論的な不確実性があるかもしれませんが、この確率を知っていても、将来のトスの結果について偶然性の不確実性が残っています。誰かが公正なコインを投げるのをどれだけ長く見ても、次のトスが頭に浮かぶことを50％以上または下回ることは決してありません。これらの用語は、機械モデリングの文献によるものです（[uncertainty quantification](https://en.wikipedia.org/wiki/Uncertainty_quantification)のこの側面に関するレビューについては、例えば、:citet:`Der-Kiureghian.Ditlevsen.2009`を参照してください）。これらの用語は言葉のわずかな乱用を構成することに注意する価値があります。*認識論的*という用語は、*知識*に関するあらゆるものを指し、したがって、哲学的な意味では、すべての不確実性は認識論的です。 

いくつかの未知の確率分布からのサンプリングデータは、データ生成分布のパラメータを推定するために使用できる情報を提供できることがわかりました。とはいえ、これが可能な速度はかなり遅くなる可能性があります。私たちのコイン投げの例（および他の多くの例）では、$1/\sqrt{n}$のレートで収束する推定量を設計するよりも良い方法はありません。ここで、$n$はサンプルサイズ（例えば、投げの数）です。これは、10から1000のオブザベーション（通常は非常に達成可能なタスク）に移行することにより、不確実性が10倍に減少するのに対し、次の1000のオブザベーションは比較的ほとんど役に立たず、1.41倍の削減しか提供しないことを意味します。これは機械学習の永続的な機能です。多くの場合、簡単に利益を得ることができますが、非常に大量のデータが必要であり、さらに利益を得るには膨大な量の計算が必要になることがよくあります。大規模言語モデルに関するこの事実の実証的レビューについては、:citet:`Revels.Lubin.Papamarkou.2016`を参照してください。 

また、統計モデリングのための言語とツールを磨きました。その過程で、条件付き確率と、統計学で最も重要な方程式の1つであるベイズの定理について学びました。これは、観測値$B$が選択されたパラメータ$A$と最初にどの程度妥当であるかを決定する事前確率$P(A)$と$A$の特定の選択がどれほど妥当であるかを決定する事前確率$P(A)$に対処する尤度項$P(B \mid A)$を介してデータによって伝達される情報を分離するための効果的なツールです。特に、このルールを適用して、検査の有効性*および*疾患自体の有病率（つまり、以前の病気）に基づいて、診断に確率を割り当てる方法を見ました。 

最後に、特定の確率分布の効果、つまり期待と分散に関する重要な質問の第1セットを導入しました。確率分布には、線形および二次的な期待以上のものがありますが、これら2つは、分布の考えられる動作に関する十分な知識をすでに提供しています。たとえば、[チェビシェフの不等式](https://en.wikipedia.org/wiki/Chebyshev%27s_inequality) には、$P(|X - \mu| \geq k \sigma) \leq 1/k^2$、$\mu$ は期待値、$\sigma^2$ は分布の分散、$k > 1$ は私たちが選択した信頼パラメータであると述べています。これは、期待値を中心とした$[-\sqrt{2} \sigma, \sqrt{2} \sigma]$区間内で少なくとも50％の確率で分布嘘から引き出すことを示しています。 

## 演習

1. より多くのデータを観察することで、結果に関する不確実性の量を任意に低いレベルまで減らすことができる例を挙げてください。
1. より多くのデータを観察しても、ある時点までの不確実性の量を減らすだけで、それ以上は減少しないという例を挙げてください。これが当てはまる理由と、この点が発生すると予想される場所を説明してください。
1. 私たちは、コイン投げの平均値への収束を経験的に実証しました。$n$サンプルを描画した後に頭が見える確率の推定値の分散を計算します。
    1. 分散は観測値の数とどのように比例しますか？
    1. チェビシェフの不等式を使用して、期待値からの偏差を制限します。
    1. それは中心極限定理とどのように関係していますか？
1. ゼロ平均と単位分散をもつ確率分布から $n$ サンプル $x_i$ を抽出すると仮定します。$z_m \stackrel{\mathrm{def}}{=} m^{-1} \sum_{i=1}^m x_i$ の平均値を計算します。すべての$z_m$にチェビシェフの不等式を個別に適用できますか？どうしてだい？
1. 確率が$P(\mathcal{A})$と$P(\mathcal{B})$の2つの事象を考えて、$P(\mathcal{A} \cup \mathcal{B})$と$P(\mathcal{A} \cap \mathcal{B})$の上限と下限を計算します。ヒント:[Venn diagram](https://en.wikipedia.org/wiki/Venn_diagram) を使用して状況をグラフ化してください。
1. たとえば、$A$、$B$、$C$ などの確率変数のシーケンスがあると仮定します。ここで、$B$ は $A$ にのみ依存し、$C$ は $B$ にのみ依存しますが、結合確率 $P(A, B, C)$ を単純化できますか？ヒント:これは [Markov chain](https://en.wikipedia.org/wiki/Markov_chain) です。
1. :numref:`subsec_probability_hiv_app`では、2つの検定の結果が独立していないと仮定します。特に、どちらかのテストだけで偽陽性率が 10%、偽陰性率が 1% であると仮定します。つまり、$P(D =1 \mid H=0) = 0.1$ と $P(D = 0 \mid H=1) = 0.01$ と仮定します。さらに、$H = 1$（感染）の検査結果は条件付きで独立している、すなわち$P(D_1, D_2 \mid H=1) = P(D_1 \mid H=1) P(D_2 \mid H=1)$であるが、健康な患者の場合、結果は$P(D_1 = D_2 = 1 \mid H=0) = 0.02$を介して結合すると仮定する。
    1. これまでに得た情報に基づいて $H=0$ を考えると、$D_1$ と $D_2$ の合同確率表を計算します。
    1. 1回の検査で陽性が戻った後に患者が陽性になる確率（$H=1$）を導き出します。以前と同じベースライン確率 $P(H=1) = 0.0015$ を仮定できます。
    1. 両方のテストが陽性になった後、患者が陽性になる確率（$H=1$）を導き出します。
1. あなたが投資銀行の資産運用会社であり、投資する株式 $s_i$ の選択肢があると仮定します。あなたのポートフォリオは、各株式のウェイト$\alpha_i$で$1$まで合計する必要があります。株価の平均リターンは$\boldsymbol{\mu} = E_{\mathbf{s} \sim P}[\mathbf{s}]$で、共分散は$\boldsymbol{\Sigma} = \mathrm{Cov}_{\mathbf{s} \sim P}[\mathbf{s}]$です。
    1. 特定のポートフォリオの期待収益を計算します $\boldsymbol{\alpha}$。
    1. ポートフォリオのリターンを最大化したい場合、投資をどのように選択すべきですか？
    1. ポートフォリオの*分散*を計算します。
    1. 分散を上限に制約したままリターンを最大化する最適化問題を定式化します。これはノーベル賞受賞の [マルコヴィッツポートフォリオ](https://en.wikipedia.org/wiki/Markowitz_model) :cite:`Mangram.2013`) です。これを解決するには、この本の範囲をはるかに超える二次計画法ソルバーが必要です。

:begin_tab:`mxnet`
[Discussions](https://discuss.d2l.ai/t/36)
:end_tab:

:begin_tab:`pytorch`
[Discussions](https://discuss.d2l.ai/t/37)
:end_tab:

:begin_tab:`tensorflow`
[Discussions](https://discuss.d2l.ai/t/198)
:end_tab:
