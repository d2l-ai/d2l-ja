# はじめに
:label:`chap_introduction`

最近まで、日常的にやり取りする可能性のあるほとんどすべてのコンピュータープログラムは、その動作を正確に指定する厳格なルールセットとしてコード化されていました。電子商取引プラットフォームを管理するアプリケーションを作成したいとしましょう。問題を熟考するためにホワイトボードを数時間巡り回した後、実用的なソリューションの広範なストロークに落ち着くかもしれません。例えば、（i）ユーザーがWebブラウザまたはモバイルアプリケーションで実行されるインターフェースを介してアプリケーションを操作する、（ii）アプリケーションが商用グレードと対話するデータベースエンジンは、各ユーザーの状態を追跡し、履歴トランザクションの記録を維持します。（iii）アプリケーションの中心にあるアプリケーションの*ビジネスロジック*（*頭脳*）は、考えられるすべての状況を対応するアクションにマッピングする一連のルールを記述します。我々のプログラムは取るべきだ 

アプリケーションの頭脳を構築するために、プログラムが処理すべきすべての一般的なイベントを列挙するかもしれません。たとえば、顧客がショッピングカートにアイテムを追加するためにクリックするたびに、プログラムはショッピングカートのデータベーステーブルにエントリを追加し、そのユーザーの ID を要求された製品の ID に関連付ける必要があります。次に、可能なすべてのコーナーケースをステップスルーし、ルールの妥当性をテストし、必要な修正を加えようとするかもしれません。ユーザーが空のカートで購入を開始するとどうなりますか？初めてそれを完全に正しく理解する開発者はほとんどいませんが（問題点を解決するためにいくつかのテストランが必要になるかもしれません）、ほとんどの場合、そのようなプログラムを書いて自信を持って起動できます
*実際の顧客に会う前に*。
多くの場合、新しい状況で機能する製品やシステムを駆動する自動化システムを手動で設計する当社の能力は、驚くべき認識上の偉業です。そして、100\ %$ の時間で動作するソリューションを考案できれば、通常、機械学習について心配する必要はありません。 

機械学習の科学者が増え続けるコミュニティにとって幸いなことに、自動化したいタスクの多くは、人間の創意工夫にそれほど簡単には曲がりません。あなたが知っている最も賢い心でホワイトボードの周りをうろついていると想像してみてください。しかし、今回は次の問題の1つに取り組んでいます。 

* 地理情報、衛星画像、および過去の天気の追跡ウィンドウを考慮して、明日の天気を予測するプログラムを作成します。
* 自由形式のテキストで表現されたファクトイドの質問を取り入れ、それに正しく答えるプログラムを書く。
* イメージが与えられ、そこに描かれているすべての人物を識別し、それぞれの周りに輪郭を描くプログラムを書く。
* ユーザーが楽しむ可能性が高いが、ブラウジングの自然な過程では遭遇する可能性が低い製品をユーザーに提示するプログラムを作成します。

これらの問題に対して、エリートプログラマーでさえ、ソリューションをゼロからコーディングするのに苦労します。理由はさまざまです。私たちが探しているプログラムは、時間とともに変化するパターンに従うことがあるので、決まった正解はありません！そのような場合、成功するソリューションは変化する世界に優雅に適応しなければなりません。また、関係（ピクセルと抽象的なカテゴリなど）が複雑すぎて、数千または数百万の計算が必要で、未知の原則に従うこともあります。画像認識の場合、潜在意識の認知プロセスがタスクを楽に実行しても、タスクを実行するために必要な正確な手順は、私たちの意識的な理解を超えています。 

*機械学習* はアルゴリズムの研究です
それは経験から学ぶことができます。機械学習アルゴリズムは、通常、観測データまたは環境との相互作用の形で、より多くの経験を蓄積するにつれて、そのパフォーマンスが向上します。これと対比して、デベロッパー自身がソフトウェアを更新する時期であることを知り、決定するまで、どんなに経験があっても、同じビジネスロジックに従う決定論的なeコマースプラットフォームとは対照的です。この本では、特にコンピュータービジョン、自然言語処理、ヘルスケア、ゲノミクスなどの多様な分野でイノベーションを推進する強力な技術である*ディープラーニング*に焦点を当てて、機械学習の基礎を説明します。 

## やる気を起こさせる例

執筆を始める前に、この本の著者は、多くの労働力と同様に、カフェインを含まなければなりませんでした。私たちは車に飛び乗って運転を始めた。iPhoneを使用して、アレックスは「Hey Siri」を呼び出し、電話の音声認識システムを目覚めさせました。そしてムーは「ブルーボトルコーヒーショップへの道順」を命じた。電話はすぐに彼の命令の書き起こしを表示しました。また、道順を尋ねていることを認識し、私たちの要求を満たすためにマップアプリケーション（アプリ）を起動しました。マップアプリを起動すると、いくつかのルートが特定されました。各ルートの横に、電話機に予想される移動時間が表示されました。このストーリーは教育上の利便性のために作り上げましたが、わずか数秒で、スマートフォンとの日常的なやり取りが複数の機械学習モデルに関与できることを実証しています。 

「アレクサ」、「OK Google」、「Hey Siri」などの*ウェイクワード*に応答するプログラムを書いていると想像してみてください。:numref:`fig_wake_word`に示すように、コンピューターとコードエディターだけで自分で部屋でコーディングしてみてください。第一原理からそのようなプログラムをどのように書きますか？考えてみて... 問題は難しい。毎秒、マイクは約44000個のサンプルを収集します。各サンプルは、音波の振幅の測定値です。生のオーディオのスニペットから、スニペットにウェイクワードが含まれているかどうかに関する信頼できる予測$\{\text{yes}, \text{no}\}$に確実にマッピングできるルールは何ですか？行き詰まっていても心配しないでください。そのようなプログラムを一から書く方法もわかりません。だからこそ、私たちは機械学習を使っています。 

![Identify a wake word.](../img/wake-word.svg)
:label:`fig_wake_word`

ここに秘訣があります。多くの場合、入力から出力へのマッピング方法をコンピューターに明示的に伝える方法がわからなくても、それでも私たちは自分たちで認知の偉業を実行することができます。つまり、「Alexa」という単語を認識するようにコンピューターをプログラムする方法がわからなくても、自分でそれを認識することができます。この機能により、どのスニペットにウェイクワードが含まれているかを示すオーディオスニペットと関連するラベルの例を含む巨大な*データセット*を収集できます。機械学習の主要なアプローチでは、システムを設計しようとはしません
*ウェイクワードを認識するために明示的に*。
代わりに、いくつかの*パラメータ*によって動作が決定される柔軟なプログラムを定義します。次に、データセットを使用して、可能な限り最良のパラメータ値、つまり、選択したパフォーマンス尺度に関してプログラムのパフォーマンスを向上させるパラメータ値を決定します。 

パラメータは、プログラムの動作を操作して回すことができるノブと考えることができます。パラメータを修正して、プログラムを*モデル*と呼びます。パラメータを操作するだけで生成できるすべての異なるプログラム (入出力マッピング) のセットは、モデルの*ファミリー*と呼ばれます。そして、私たちのデータセットを使ってパラメータを選択するメタプログラムは、*学習アルゴリズム*と呼ばれています。 

学習アルゴリズムに取り組む前に、問題を正確に定義し、入力と出力の正確な性質を特定し、適切なモデルファミリーを選択する必要があります。この場合、モデルはオーディオのスニペットを*input* として受け取り、モデルは $\{\text{yes}, \text{no}\}$ の中から*output* として選択を生成します。すべてが計画どおりに進んだ場合、スニペットにウェイクワードが含まれているかどうかについて、モデルの推測は一般的に正しいでしょう。 

適切なモデルファミリーを選択した場合、「Alexa」という単語が聞こえるたびにモデルが「はい」になるように、ノブの設定が1つ存在する必要があります。ウェイクワードの正確な選択は任意であるため、ノブの別の設定を介して、「アプリコット」という単語が聞こえたときにのみ「はい」を発火できる、十分に豊富なモデルファミリーが必要になるでしょう。同じモデルファミリーが「Alexa」認識と「Apricot」認識に適していると予想されます。なぜなら、それらは直感的には似たようなタスクに見えるからです。ただし、画像からキャプションに、または英語の文から中国語の文にマッピングする場合など、根本的に異なる入力または出力を処理する場合は、まったく別のモデルファミリーが必要になる場合があります。 

ご想像のとおり、すべてのノブをランダムに設定した場合、モデルが「Alexa」、「Apricot」、またはその他の英語の単語を認識する可能性はほとんどありません。機械学習では、*学習*は、モデルから望ましい動作を強制するノブの正しい設定を発見するプロセスです。言い換えれば、私たちはデータを使ってモデルを*トレーニング*します。:numref:`fig_ml_loop`に示すように、トレーニングプロセスは通常次のようになります。 

1. 役に立たないランダムに初期化されたモデルから始めます。
1. データの一部を取得します (例:オーディオスニペットと対応する $\{\text{yes}, \text{no}\}$ ラベル)。
1. ノブを微調整して、これらの例で評価したとおりにモデルのパフォーマンスを向上させます。
1. モデルがすごいものになるまで、手順2と3を繰り返します。

![A typical training process.](../img/ml-loop.svg)
:label:`fig_ml_loop`

要約すると、ウェイクワードレコグナイザーをコーディングするのではなく、大きなラベル付きデータセットが提示された場合、ウェイクワードを認識することを*学習*できるプログラムをコーディングします。プログラムの動作を決定するこの行為は、データセットを*データによるプログラミング* として提示することによって考えることができます。つまり、機械学習システムに多くの猫と犬の例を提供することで、猫検出器を「プログラム」することができます。このようにして、検出器は最終的に猫であれば非常に大きな正の数を、犬であれば非常に大きな負の数を、確信が持てない場合はゼロに近いものを放出することを学習します。これは、機械学習ができることの表面をほとんど傷つけません。ディープラーニングは、後で詳しく説明しますが、機械学習の問題を解決する多くの一般的な方法の1つにすぎません。 

## 主要コンポーネント

ウェイクワードの例では、オーディオスニペットとバイナリラベルで構成されるデータセットについて説明し、スニペットから分類へのマッピングを近似するようにモデルをトレーニングする方法について手を振った感覚を与えました。ラベルが知られている例で構成されるデータセットを与えられた既知の入力に基づいて指定された未知のラベルを予測しようとするこの種の問題は、*教師付き学習*と呼ばれます。これは、多くの種類の機械学習問題の1つにすぎません。他の品種を探る前に、私たちがどのような機械学習の問題に取り組んでも、私たちの周りに続くいくつかのコアコンポーネントにもっと光を当てたいと思います。 

1. 私たちが学ぶことができる*データ*。
1. データを変換する方法の*モデル*。
1. モデルの動作がどの程度 (または悪い) かを定量化する*目的関数*。
1. モデルのパラメーターを調整して目的関数を最適化する*アルゴリズム*。

### データ

言うまでもなく、データなしではデータサイエンスを成し遂げることはできません。正確にはデータ*とは何かを熟考するページが何百も失われる可能性がありますが、ここでは、関心のあるデータセットの主要な特性に焦点を当てます。一般的に、私たちは一連の例に関係しています。データを有効に扱うためには、通常、適切な数値表現を考え出す必要があります。各*example* (または*データポイント*、*データインスタンス*、*sample*) は、通常、モデルが予測を行う必要がある*features* (*covariates* または*inputs* と呼ばれることもあります) と呼ばれる一連の属性で構成されます。教師あり学習問題における私たちの目標は、モデルの入力の一部ではない、*ラベル* (または*ターゲット*) と呼ばれる特別な属性の値を予測することです。 

画像データを扱う場合、各例は個々の写真（フィーチャ）と、写真が属するカテゴリ（ラベル）を示す数字で構成されます。写真は、各ピクセル位置における赤、緑、青の光の明るさを表す 3 つの数値グリッドとして数値で表されます。たとえば、$200\times 200$ のカラー写真は $200\times200\times3=120000$ の数値で構成されます。 

あるいは、電子医療記録データを使用して、特定の患者が今後30日間生存する可能性を予測するタスクに取り組むこともできます。ここでは、私たちの機能は、年齢、バイタルサイン、併存疾患、現在の薬、最近の手順など、すぐに利用できる属性と頻繁に記録される測定のコレクションで構成されている可能性があります。トレーニングに使用できるラベルは、履歴データの各患者が30日以内に生存したかどうかを示すバイナリ値です。 

そのような場合、すべての例が同じ数の数値的特徴によって特徴付けられる場合、入力は固定長ベクトルであり、ベクトルの（一定の）長さをデータの*次元性*と呼びます。ご想像のとおり、固定長の入力は便利で、心配する複雑さが1つ少なくなります。ただし、すべてのデータを*固定長* ベクトルとして簡単に表現できるわけではありません。顕微鏡の画像は標準的な装置から得られると予想されるかもしれませんが、インターネットから採掘された画像がすべて同じ解像度または形状で表示されることは期待できません。画像については、すべてを標準サイズに切り抜くことを検討するかもしれませんが、その戦略では今のところしか得られません。切り取られた部分の情報が失われる危険があります。さらに、テキストデータは固定長表現にさらに頑固に抵抗します。Amazon、IMDb、トリップアドバイザーなどのeコマースサイトに残されたカスタマーレビューを考えてみましょう。一部は短い：「臭い！」。他の人はページをめぐって争う.従来の方法に対するディープラーニングの主な利点の1つは、最新のモデルが*さまざまな長さ*のデータを処理できる比較優位性です。 

一般的に、データが多ければ多いほど、仕事は楽になります。より多くのデータがあると、より強力なモデルをトレーニングでき、先入観にあまり依存しなくなります。（比較的）小規模データからビッグデータへの体制転換は、現代のディープラーニングの成功に大きく貢献しています。要点を理解するために、ディープラーニングで最もエキサイティングなモデルの多くは、大きなデータセットがないと機能しません。スモールデータ体制で働くものもありますが、従来のアプローチに勝るものはありません。 

最後に、大量のデータを持ち、それを巧みに処理するだけでは十分ではありません。*正しい*データが必要です。データに誤りがたくさんある場合、または選択した特徴量が目標とする対象量を予測できない場合、学習は失敗します。状況は決まり文句によってうまく捉えられています。
*ガベージイン、ガベージアウト*。
さらに、予測パフォーマンスの低下だけが潜在的な結果ではありません。予測ポリシング、履歴書スクリーニング、融資に使用されるリスクモデルなど、機械学習の機密性の高いアプリケーションでは、ガベージデータの影響に特に注意する必要があります。一般的な故障モードの 1 つは、一部の人々のグループがトレーニングデータに含まれていないデータセットで発生します。これまでに黒い肌を見たことがない野生の皮膚がん認識システムを適用することを想像してみてください。失敗は、データが一部のグループを過小評価しているだけでなく、社会的偏見を反映している場合にも発生する可能性があります。たとえば、過去の採用決定を使用して、履歴書のスクリーニングに使用される予測モデルをトレーニングすると、機械学習モデルが不注意に過去の不正を捉えて自動化する可能性があります。これはすべて、データサイエンティストが積極的に共謀したり、気づいたりしなくても起こり得ることに注意してください。 

### モデル

ほとんどの機械学習は、ある意味でデータを変換することを含みます。写真を取り込んで笑顔を予測するシステムを構築したいと思うかもしれません。あるいは、一連のセンサーの読み取り値を取り込んで、読み取り値がどの程度正常か異常かを予測したい場合があります。*model* とは、あるタイプのデータを取り込み、異なるタイプの予測を吐き出すための計算機構を示します。特に、データから推定できる統計モデルに関心があります。単純なモデルは適切な単純な問題に完全に対処できますが、この本で焦点を当てている問題は、古典的な方法の限界を広げています。ディープラーニングは、主に焦点を当てた一連の強力なモデルによって、従来のアプローチと区別されます。これらのモデルは、上から下に連鎖するデータの多くの連続的な変換で構成されているため、*ディープラーニング* という名前が付けられています。ディープモデルについて議論する途中で、いくつかのより伝統的な方法についても議論します。 

### 客観的機能

以前、経験からの学習として機械学習を導入しました。ここで*学ぶ*とは、あるタスクで時間をかけて改善することを意味します。しかし、何が改善を構成するかは誰に言いますか？モデルの更新を提案できると想像するかもしれませんが、提案された更新が改善を構成するのか拒否したのかについて意見が合わない人もいます。 

学習機械の正式な数学的システムを開発するには、モデルがどれほど良い（または悪い）かを公式に測定する必要があります。機械学習、およびより一般的な最適化では、これらを*目的関数*と呼びます。慣例として、私たちは通常、低いほど良いように目的関数を定義します。これは単なる慣習です。符号を反転させることで、高いほど良い関数を取って、質的には同一であるが、低いほど良い新しい関数に変えることができます。低いほど良いので、これらの関数は時々呼ばれます
*損失関数*。

数値を予測しようとする場合、最も一般的な損失関数は*二乗誤差*、つまり予測とグラウンドトゥルースターゲットの差の二乗です。分類の最も一般的な目的は、誤り率を最小限に抑えることです。つまり、予測がグラウンドトゥルースと一致しない例の割合です。一部の目的（二乗誤差など）は最適化が簡単ですが、他の目的（誤り率など）は、非微分可能性やその他の複雑さのために直接最適化するのが困難です。このような場合、*サロゲート目標*を最適化するのが一般的です。 

最適化中、損失はモデルのパラメーターの関数と考え、トレーニングデータセットを定数として扱います。トレーニング用に収集されたいくつかの例で構成されるセットで発生する損失を最小限に抑えることで、モデルのパラメーターの最適な値を学習します。しかし、トレーニングデータをうまく処理しても、目に見えないデータでうまくいくとは限りません。そのため、通常、利用可能なデータを2つのパーティションに分割します。モデルパラメーターを学習するための*トレーニングデータセット*（または*トレーニングセット*）と、評価のために保持される*テストデータセット*（または*テストセット*）です。一日の終わりには、通常、両方のパーティションでモデルがどのように機能するかを報告します。トレーニングのパフォーマンスは、実際の最終試験の準備に使用される模擬試験で学生が達成するスコアに似ていると考えることができます。結果が期待できるものであっても、期末試験の成功を保証するものではありません。勉強の過程で、学生は練習問題を覚え始めるかもしれません。トピックを習得しているように見えますが、実際の最終試験でこれまでに見られなかった問題に直面すると落ち着きます。モデルがトレーニングセットでうまく機能するが、目に見えないデータに一般化できない場合、トレーニングデータに*過剰適合*していると言います。 

### 最適化アルゴリズム

データソースと表現、モデル、明確に定義された目的関数が得られたら、損失関数を最小化するための最良のパラメーターを検索できるアルゴリズムが必要です。ディープラーニングの一般的な最適化アルゴリズムは、*勾配降下法*と呼ばれるアプローチに基づいています。要するに、この方法は、各ステップで、パラメータを少しだけ摂動させた場合、トレーニングセットの損失がどの方向に動くかを各パラメータについてチェックします。次に、損失を下げる方向にパラメータを更新します。 

## 機械学習の問題の種類

私たちのやる気を起こさせる例のウェイクワード問題は、機械学習が取り組むことができる多くの問題の1つにすぎません。読者をさらにやる気にさせ、本全体を通して私たちが従ういくつかの共通言語を提供するために、機械学習の問題定式化の概要を説明します。 

### 教師あり学習

教師あり学習は、フィーチャとラベルの両方を含むデータセットが与えられ、入力フィーチャからラベルを予測するモデルを作成するタスクを記述します。各フィーチャとラベルのペアを例と呼びます。コンテキストが明確な場合、対応するラベルが不明な場合でも、入力のコレクションを指すために*examples* という用語を使用することがあります。パラメータを選択するために、私たち（スーパーバイザー）がラベル付きの例で構成されるデータセットをモデルに提供するため、監督が役立ちます。確率論的には、通常、入力フィーチャからラベルの条件付き確率を推定することに関心があります。これは機械学習におけるいくつかのパラダイムの1つにすぎませんが、教師あり学習は業界で成功している機械学習のアプリケーションの大部分を占めています。その理由の1つは、多くの重要なタスクが、特定の利用可能なデータのセットを考慮して、未知の何かの確率を推定することとして明確に説明できるためです。 

* コンピューター断層撮影画像から、がんとがんではないかを予測します。
* 英語の文を考えると、フランス語の正しい翻訳を予測します。
* 今月の財務報告データに基づいて、来月の株価を予測します。

教師あり学習の問題はすべて、「入力特徴を与えられたラベルを予測する」という簡単な説明によって捉えられますが、教師あり学習は、入力と出力のタイプ、サイズ、および量に応じて、さまざまな形式をとることができ、（他の考慮事項の中でも）大量のモデリング決定を必要とします。たとえば、任意の長さのシーケンスを処理したり、固定長のベクトル表現を処理したりするために、さまざまなモデルを使用します。この本を通して、これらの問題の多くを詳しく見ていきます。 

非公式には、学習プロセスは次のようになります。まず、特徴がわかっている多数の例を取り出し、それらからランダムなサブセットを選択し、それぞれのグラウンドトゥルースラベルを取得します。これらのラベルは、すでに収集された入手可能なデータである場合があります（例：患者は翌年に死亡しましたか？）また、データにラベルを付けるために人間の注釈者を使用する必要がある場合もあります（たとえば、画像をカテゴリに割り当てるなど）。これらの入力と対応するラベルが一緒になって、トレーニングセットを構成します。トレーニングデータセットを教師あり学習アルゴリズムに送ります。教師あり学習アルゴリズムは、データセットを入力として受け取り、別の関数、つまり学習されたモデルを出力する関数です。最後に、その出力を対応するラベルの予測として使用して、学習したモデルにこれまで見られなかった入力を与えることができます。完全なプロセスは:numref:`fig_supervised_learning`に描かれています。 

![Supervised learning.](../img/supervised-learning.svg)
:label:`fig_supervised_learning`

#### リグレッション

おそらく、頭を包み込む最も簡単な教師あり学習タスクは、*回帰*でしょう。たとえば、住宅販売のデータベースから収集された一連のデータを考えてみましょう。各行が別の家に対応し、各列が家の平方フィート、寝室の数、バスルームの数、町の中心までの時間（徒歩）数などの関連する属性に対応するテーブルを作成するとします。このデータセットでは、各例は特定の家で、対応する特徴ベクトルはテーブルの 1 行になります。ニューヨークまたはサンフランシスコに住んでいて、Amazon、グーグル、マイクロソフト、またはFacebookのCEOではない場合、あなたの家の特徴ベクトル（平方映像、寝室数、バスルーム数、徒歩距離）は、$[600, 1, 1, 60]$のようになります。ただし、ピッツバーグに住んでいる場合は、$[3000, 4, 3, 10]$のように見えるかもしれません。このような固定長特徴ベクトルは、ほとんどの従来の機械学習アルゴリズムに不可欠です。 

問題を回帰させるのは、実際にはターゲットの形です。あなたが新しい家を求めて市場に出ているとしましょう。上記のような機能をいくつか考えると、住宅の公正な市場価値を見積もることができます。ここのデータは過去の住宅リストで構成され、ラベルは観測された販売価格である可能性があります。ラベルが（ある間隔内であっても）任意の数値をとる場合、これを*回帰*問題と呼びます。目標は、予測が実際のラベル値に近似するモデルを作成することです。 

実際的な問題の多くは、回帰問題として簡単に説明できます。ユーザーが映画に割り当てるレーティングを予測することは、回帰問題と考えることができます。2009年にこの偉業を達成するための優れたアルゴリズムを設計した場合、[1-million-dollar Netflix prize](https://en.wikipedia.org/wiki/Netflix_Prize)を獲得した可能性があります。入院中の患者の滞在期間を予測することも回帰の問題です。経験則としては、どれくらい？* または*いくつですか？* 問題は回帰を示唆するはずです、例えば: 

* この手術は何時間かかりますか？
* この町は今後6時間でどれくらいの雨が降るだろうか？

これまで機械学習に取り組んだことがなくても、おそらく非公式に回帰問題に取り組んだことがあるでしょう。たとえば、排水管を修理し、請負業者が下水管からガンクを取り除くのに3時間を費やしたとします。それから彼はあなたに350ドルの請求書を送った。ここで、あなたの友人が同じ請負業者を2時間雇い、250ドルの請求書を受け取ったと想像してください。次に、誰かが次のガンク除去請求書にどれだけ期待できるかを尋ねた場合、労働時間が増えると費用がかかるなど、合理的な仮定を立てる可能性があります。また、基本料金がいくらかあり、請負業者が1時間ごとに請求すると想定することもできます。これらの仮定が当てはまる場合、これら2つのデータ例を考えれば、請負業者の価格体系をすでに特定できます。1時間あたり100ドルと自宅に50ドルを加えたものです。それだけ従えば、線形回帰の背後にあるハイレベルな考え方をすでに理解しているでしょう。 

この場合、請負業者の価格に正確に一致するパラメータを生成できます。これは不可能な場合があります。たとえば、分散の一部が2つの特徴以外のいくつかの要因に起因する場合などです。このような場合、予測値と観測値の間の距離を最小にするモデルを学習しようとします。ほとんどの章では、二乗誤差損失関数の最小化に焦点を当てます。後で見るように、この損失は、データがガウスノイズによって破壊されたという仮定に対応します。 

#### 分類

回帰モデルは対処するのに最適ですが、*いくつですか？*質問、多くの問題はこのテンプレートに快適に曲がりません。たとえば、モバイルアプリ用の小切手スキャン機能を開発したい銀行を考えてみましょう。理想的には、顧客は小切手の写真を撮るだけで、アプリは画像からテキストを自動的に認識します。手書きの各文字に対応する画像パッチをセグメント化する能力があると仮定すると、残りの主なタスクは、既知のセットの中のどの文字が各画像パッチに描かれているかを決定することです。この種類の*どれ？* 問題は*分類* と呼ばれ、回帰に使用されるものとは異なる一連のツールが必要ですが、多くの手法が引き継がれます。 

*分類*では、モデルに画像内のピクセル値などの特徴を調べ、いくつかの離散的なオプションセットのうち、例が属する*カテゴリ*（*クラス*と呼ばれることもあります）を予測します。手書きの数字の場合、0から9の数字に対応する10個のクラスがあります。最も単純な分類形式は、クラスが2つしかない場合で、これを*バイナリ分類*と呼んでいます。たとえば、データセットは動物の画像で構成され、ラベルはクラス$\mathrm{\{cat, dog\}}$である可能性があります。回帰では、数値を出力するリグレッサーを探し、分類では分類器を探しました。その出力は予測されたクラス割り当てです。 

本がより技術的になるにつれて説明する理由から、「cat」や「dog」など、ハードカテゴリ割り当てのみを出力できるモデルを最適化するのは難しい場合があります。このような場合、通常は、代わりに確率言語でモデルを表現する方がはるかに簡単です。例の特徴を考えると、私たちのモデルは可能な各クラスに確率を割り当てます。クラスが $\mathrm{\{cat, dog\}}$ である動物分類の例に戻ると、分類器は画像を見て、画像が猫である確率を 0.9 と出力する場合があります。この数字は、画像が猫を描写していることを分類器が90％確信していると解釈できます。予測されたクラスの確率の大きさは、不確実性の 1 つの概念を伝えます。不確実性の概念はそれだけではありません。他の概念については、より高度な章で説明します。 

可能なクラスが 3 つ以上ある場合、問題を*マルチクラス分類* と呼びます。一般的な例には、手書き文字認識$\mathrm{\{0, 1, 2, ... 9, a, b, c, ...\}}$が含まれます。二乗誤差損失関数を最小化しようとして回帰問題を攻撃しましたが、分類問題の共通損失関数は*クロスエントロピー*と呼ばれ、その名前は後続の章で情報理論の紹介を通じてわかりやすく説明できます。 

最も可能性の高いクラスは、必ずしも決定に使用するクラスではないことに注意してください。:numref:`fig_death_cap`に示すように、裏庭で美しいキノコを見つけたとします。 

![Death cap - do not eat!](../img/death-cap.jpg)
:width:`200px`
:label:`fig_death_cap`

ここで、分類器を構築し、写真に基づいてキノコが有毒かどうかを予測するように訓練したとします。ポイズン検出分類器が:numref:`fig_death_cap`にデスキャップを含む確率が0.2であると出力したとします。言い換えれば、分類器は、私たちのキノコがデスキャップではないことを80％確信しています。それでも、それを食べるのはばかでなければならないでしょう。それは、おいしい夕食の特定の利益は、それで死ぬリスクの 20\% の価値がないからです。言い換えれば、不確実なリスクの影響は、利益をはるかに上回ります。したがって、キノコを食べるかどうかを決定するためには、起こりそうな結果とそれぞれに関連する利益または害の両方に依存する、各行動に関連する予想される不有用性を計算する必要があります。この場合、キノコを食べることによって生じる不能は$0.2 \times \infty + 0.8 \times 0 = \infty$であるのに対し、それを捨てることの損失は$0.2 \times 0 + 0.8 \times 1 = 0.8$であるかもしれません。私たちの注意は正当化されました。菌学者が言うように、:numref:`fig_death_cap`のキノコは実際には死の帽子です。 

分類は、バイナリ分類やマルチクラス分類よりもはるかに複雑になる可能性があります。たとえば、階層的に構造化されたクラスに対処する分類のいくつかの変形があります。そのような場合、すべての誤りが等しいわけではありません。誤りを犯さなければならない場合は、遠いクラスではなく関連するクラスに誤分類する方がよいかもしれません。通常、これは*階層分類*と呼ばれます。インスピレーションを得るために、動物を階層的に整理した[Linnaeus](https://en.wikipedia.org/wiki/Carl_Linnaeus)を思い浮かべるかもしれません。 

動物分類の場合、プードルをシュナウザーと間違えるのはそれほど悪くないかもしれませんが、私たちのモデルは、プードルを恐竜と混同すると大きなペナルティを払うことになります。どの階層が関連するかは、モデルの使用方法によって異なる場合があります。たとえば、ガラガラヘビとガーターヘビは系統樹に近いかもしれませんが、ガラガラをガーターと間違えると致命的になる可能性があります。 

#### タグ付け

一部の分類問題は、バイナリまたはマルチクラスの分類設定にうまく適合します。たとえば、猫と犬を区別するために通常のバイナリ分類器をトレーニングできます。コンピュータビジョンの現状を考えると、市販のツールでこれを簡単に行うことができます。それでも、モデルがどれほど正確であっても、分類器が、4匹の動物が登場するドイツの人気のあるおとぎ話（:numref:`fig_stackedanimals`）である*ブレーメンのタウンミュージシャン*の画像に遭遇すると、問題が発生する可能性があります。 

![A donkey, a dog, a cat, and a rooster.](../img/stackedanimals.png)
:width:`300px`
:label:`fig_stackedanimals`

ご覧のとおり、写真には猫、オンドリ、犬、ロバが描かれており、背景にいくつかの木があります。このような画像に遭遇すると予想される場合、マルチクラス分類は適切な問題の定式化ではないかもしれません。代わりに、画像が猫、犬、ロバを描いていると言うオプションをモデルに与えたいと思うかもしれません。
*そして*オンドリ。

相互に排他的ではないクラスを予測することを学習する問題は、*マルチラベル分類*と呼ばれます。自動タグ付けの問題は、通常、マルチラベル分類問題として最もよく説明されます。「機械学習」、「テクノロジー」、「ガジェット」、「プログラミング言語」、「Linux」、「クラウドコンピューティング」、「AWS」など、人々が技術ブログの投稿に適用する可能性のあるタグを考えてみてください。一般的な記事には、5～10 個のタグが適用されている場合があります。通常、タグは何らかの相関構造を示します。「クラウドコンピューティング」に関する投稿は「AWS」に言及する可能性が高く、「機械学習」に関する投稿は「GPU」に言及する可能性が高い。 

このようなタグ付けの問題は、膨大なラベルセットに悪影響を与えることがあります。国立医学図書館は、PubMedで索引付けされる各記事を、約28000個のタグのコレクションである医学科目見出し（MeSH）オントロジーから引き出された一連のタグと関連付ける多くの専門注釈者を雇用しています。記事を正しくタグ付けすることは、研究者が文献の徹底的なレビューを行うことを可能にするため、重要です。これは時間のかかるプロセスであり、アノテーターは通常、アーカイブとタグ付けの間に1年の遅れがあります。機械学習は、各記事が適切な手動レビューを受けることができるまで、暫定的なタグを提供できます。実際、数年間、BioASQ組織はこのタスクのために[hosted competitions](http://bioasq.org/)を持っています。 

#### 検索

情報検索の分野では、アイテムのセットにランキングを課すことがよくあります。ウェブ検索を例にとってみましょう。目標は、特定のページがクエリに関連しているかどうか*判断することではなく、関連する一連の結果の中で特定のユーザーに最も目立つように表示する必要があるかどうかを判断することです。考えられる解決策の1つは、最初にセット内のすべての要素にスコアを割り当て、次に最高評価の要素を取得することです。Google検索エンジンの背後にある元の秘密のソースである[PageRank](https://en.wikipedia.org/wiki/PageRank)は、そのようなスコアリングシステムの初期の例でした。独特なことに、PageRankによって提供されたスコアリングは実際のクエリに依存しませんでした。代わりに、関連する候補のセットを特定するために単純な関連性フィルターに依存し、PageRankを使用してより信頼できるページに優先順位を付けました。現在、検索エンジンは機械学習と行動モデルを使用して、クエリに依存する関連性スコアを取得しています。このテーマに専念する学術会議全体があります。 

#### レコメンダーシステム
:label:`subsec_recommender_systems`

レコメンダーシステムは、検索とランキングに関連する別の問題設定です。一連の関連項目をユーザーに表示することが目的である限り、問題は同様です。主な違いは、レコメンダーシステムのコンテキストで特定のユーザーに*パーソナライゼーション*を重視していることです。たとえば、映画のおすすめの場合、サイエンスフィクションファン向けの結果ページと、ピーターセラーズのコメディーの愛好家向けの結果ページが大幅に異なる場合があります。同様の問題が、小売商品、音楽、ニュースのおすすめなど、他のおすすめ設定でポップアップ表示されます。 

場合によっては、顧客が特定の製品をどれだけ気に入ったかを伝える明確なフィードバックを提供することがあります（例：Amazon、IMDb、Goodreadsでの製品評価とレビュー）。また、プレイリストのタイトルをスキップするなど、不満を示したり、曲が文脈上不適切であることを示したりするなど、暗黙のフィードバックを提供する場合もあります。最も単純な定式化では、これらのシステムは、予想される星評価や特定のユーザーが特定のアイテムを購入する確率など、ある程度のスコアを推定するように訓練されています。 

このようなモデルがあれば、任意のユーザーに対して、最大のスコアを持つオブジェクトのセットを取得し、ユーザーに推奨することができます。本番システムはかなり高度で、そのようなスコアを計算する際に詳細なユーザーアクティビティとアイテムの特性を考慮します。:numref:`fig_deeplearning_amazon`は、Astonの好みをキャプチャするように調整されたパーソナライゼーションアルゴリズムに基づいてAmazonが推奨するディープラーニングブックを表示します。 

![Deep learning books recommended by Amazon.](../img/deeplearning-amazon.jpg)
:label:`fig_deeplearning_amazon`

莫大な経済的価値にもかかわらず、予測モデルの上に素朴に構築されたレコメンデーションシステムは、いくつかの深刻な概念上の欠陥に苦しんでいます。まず、*検閲されたフィードバック*のみを観察します。ユーザーは、自分が強く感じている映画を優先的に評価します。たとえば、5 段階評価では、項目に 1 つ星と 5 つ星の数が多いが、3 つ星の評価が目立つほど少ないことに気付くかもしれません。さらに、現在の購入習慣は、現在実施されているレコメンデーションアルゴリズムの結果であることが多いですが、学習アルゴリズムでは必ずしもこの詳細を考慮しているわけではありません。したがって、フィードバックループが形成され、レコメンダーシステムがアイテムを優先的にプッシュし、（購入が増えるため）より良いものと判断され、さらに頻繁に推奨されるようになります。検閲、インセンティブ、フィードバックループへの対処方法に関するこれらの問題の多くは、重要なオープンリサーチクエスチョンです。 

#### シーケンス学習

これまで、いくつかの固定数の入力があり、固定数の出力を生成する問題を見てきました。たとえば、平方フィート、寝室の数、バスルームの数、ダウンタウンまでの移動時間など、固定された一連のフィーチャを考慮して住宅価格を予測することを検討しました。また、（固定次元の）画像から、固定数のクラスの中でそれぞれが属する予測確率へのマッピングと、ユーザーIDと製品IDのみに基づいて購入に関連する星評価を予測することについても説明しました。このような場合、モデルがトレーニングされると、各テスト例がモデルに入力されると、すぐに忘れられます。私たちは、連続する観測は独立しており、したがって、この文脈を保持する必要はないと仮定しました。 

しかし、ビデオスニペットをどのように扱うべきでしょうか？この場合、各スニペットは異なる数のフレームで構成されている可能性があります。また、前のフレームまたは次のフレームを考慮すると、各フレームで何が起こっているのかを推測するほうがはるかに強くなる可能性があります。言語についても同じことが言えます。ディープラーニングでよく知られている問題の1つは、機械翻訳です。これは、あるソース言語の文を取り込み、別の言語で翻訳を予測するタスクです。 

これらの問題は医学でも起こります。集中治療室の患者を監視し、次の24時間で死亡するリスクがあるしきい値を超えるたびにアラートを発するモデルが必要になる場合があります。ここでは、患者の病歴について知っていることを1時間ごとにすべて捨てるのではなく、最新の測定値のみに基づいて予測を行います。 

これらの問題は、機械学習の最もエキサイティングなアプリケーションの1つであり、*シーケンス学習*の例です。これらには、一連の入力を取り込むか、出力のシーケンス（またはその両方）を出力するモデルが必要です。具体的には、*シーケンス間学習* は、入力と出力の両方が可変長シーケンスで構成される問題を考慮します。例としては、機械翻訳や音声からテキストへの文字起こしなどがあります。すべてのタイプのシーケンス変換を考慮することは不可能ですが、次の特殊なケースは言及する価値があります。 

**タグ付けと解析**。
これには、テキストシーケンスに属性による注釈を付けることが含まれます。ここで、入力と出力は*整列*されています。つまり、それらは同じ番号で、対応する順序で発生します。たとえば、*品詞（PoS）タグ付け*では、文中のすべての単語に対応する品詞、つまり「名詞」または「直接目的」に注釈を付けます。あるいは、連続する単語のどのグループが*人*、*場所*、または*組織*のような名前付きエンティティを参照しているかを知りたいかもしれません。以下の漫画的に単純な例では、文中のすべての単語について、それが名前付きエンティティ（「Ent」としてタグ付けされた）の一部であるかどうかを示したいだけかもしれません。

```text
Tom has dinner in Washington with Sally
Ent  -    -    -     Ent      -    Ent
```

**自動音声認識**。
音声認識では、入力シーケンスは話者の音声録音（:numref:`fig_speech`）であり、出力は話者の発言のトランスクリプトです。課題は、テキストよりもはるかに多くのオーディオフレーム（サウンドは一般的に8kHzまたは16kHzでサンプリングされます）があることです。つまり、数千のサンプルが1つの話し言葉に対応している可能性があるため、オーディオとテキストの間に1：1の対応がないということです。これらは、出力が入力よりもはるかに短い、シーケンス間学習の問題です。 

![`-D-e-e-p- L-ea-r-ni-ng-` in an audio recording.](../img/speech.png)
:width:`700px`
:label:`fig_speech`

**テキスト読み上げ**。
これは自動音声認識の逆です。ここで、入力はテキストで、出力はオーディオファイルです。この場合、出力は入力よりもはるかに長くなります。人間は、低品質のオーディオからでも音声を認識するのが非常に得意ですが、コンピューターにその偉業を実行させることは手ごわい挑戦です。 

**機械翻訳**。
機械翻訳では、対応する入力と出力が同じ順序で発生する音声認識の場合とは異なり、アライメントされていないデータは新たな課題を提起します。ここで、入力シーケンスと出力シーケンスは異なる長さを持つことができ、それぞれのシーケンスの対応する領域は異なる順序で表示される場合があります。ドイツ人が動詞を文末に置くという独特の傾向を示す次の例を考えてみましょう。

```text
German:           Haben Sie sich schon dieses grossartige Lehrwerk angeschaut?
English:          Did you already check out this excellent tutorial?
Wrong alignment:  Did you yourself already this excellent tutorial looked-at?
```

関連する多くの問題が他の学習タスクに現れます。たとえば、ユーザーがWebページを読む順序を決定することは、2次元のレイアウト分析の問題です。対話の問題にはあらゆる種類の追加の複雑さがあり、次に何を言うかを決定するには、現実世界の知識と長い時間的距離にわたる会話の以前の状態を考慮する必要があります。これらは活発な研究分野です。 

### 教師なし学習と自己教師あり学習

前の例では、教師あり学習に焦点を当てていました。ここでは、特徴と対応するラベル値の両方を含む巨大なデータセットをモデルに供給します。教師付き学習者は、非常に専門的な仕事と非常に独裁的な上司と考えることができます。上司は肩越しに立ち、状況から行動へのマッピングを学ぶまで、あらゆる状況で何をすべきかを正確に伝えます。そのような上司のために働くことはかなり下品に聞こえます。一方、そのような上司を喜ばせるのはかなり簡単です。できるだけ早くパターンを認識し、その行動を真似するだけです。 

逆の状況を考えると、自分が何をしてほしいのか分からない上司のために働くのはイライラするかもしれません。しかし、データサイエンティストになるつもりなら、それに慣れたほうがいいでしょう。ボスはあなたに大量のデータを渡して、それを使ってデータサイエンスをやるように言うかもしれません！* これは曖昧に聞こえます。私たちはこのクラスの問題を「教師なし学習」と呼んでおり、私たちが尋ねることができる質問の種類と数は、私たちの創造性によってのみ制限されます。教師なし学習技術については、後の章で取り上げます。今のあなたの食欲をそそるために、私たちはあなたが尋ねるかもしれない以下の質問のいくつかを説明します。 

* 少数のプロトタイプを見つけることはできますか
データを正確に要約しているのか？写真のセットがあれば、風景写真、犬、赤ちゃん、猫、山頂の写真にグループ化できますか？同様に、ユーザーのブラウジングアクティビティのコレクションがある場合、それらを同様の行動を持つユーザーにグループ化できますか？この問題は通常、*クラスタリング*として知られています。
* 少数のパラメータを見つけることはできますか
データの関連する特性を正確に捉えるのは何ですか？ボールの軌道は、ボールの速度、直径、質量によってよく記述されます。仕立て屋は、衣服をフィットさせる目的で、人体の形状をかなり正確に記述する少数のパラメータを開発しました。これらの問題は、*部分空間推定* と呼ばれます。依存性が線形の場合は、*主成分分析*と呼ばれます。
* （任意に構造化された）オブジェクトの表現はありますか
ユークリッド空間で、シンボリックプロパティがうまく一致するようにしますか？これは、「ローマ」$-$「イタリア」$+$「フランス」$=$「パリ」など、エンティティとその関係を記述するために使用できます。
* 根本原因の説明はありますか
私たちが観察するデータの多くは？たとえば、住宅価格、汚染、犯罪、場所、教育、給与に関する人口統計データがある場合、経験的データに基づいてそれらがどのように関連しているかを発見できますか？*因果関係*に関する分野と
*確率的グラフィカル・モデル*は、そのような問題に取り組みます。
* 教師なし学習におけるもう一つの重要で刺激的な最近の進展
ディープ・ジェネレーティブ・モデルの出現です。これらのモデルは、データ$p(\mathbf{x})$の密度を明示的または*暗黙的に*推定します。トレーニングが完了したら、生成モデルを使用して、その可能性に応じて例をスコアリングするか、学習した分布から合成例をサンプリングできます。ジェネレーティブモデリングにおける初期のディープラーニングのブレークスルーは、*変分オートエンコーダー* :cite:`Kingma.Welling.2014`の発明によってもたらされ、*敵対的生成ネットワーク* :cite:`Goodfellow.Pouget-Abadie.Mirza.ea.2014`の開発を続けました。最近の進歩には、流れの正規化、拡散モデル、スコアベースのモデルが含まれます。 

教師なし学習の主要な発展は、ラベルなしデータのいくつかの側面を活用して監督を提供する技術である「自己教師あり学習」の台頭です。テキストについては、ラベル付けの手間をかけずに、大きなコーパスで周囲の単語（コンテキスト）を使用してランダムにマスクされた単語を予測することで、「空白を埋める」ようにモデルをトレーニングできます。:cite:`Devlin.Chang.Lee.ea.2018`！画像の場合、同じ画像:cite:`Doersch.Gupta.Efros.2015`の2つの切り取られた領域間の相対的な位置を伝えるか、画像の残りの部分に基づいて画像のオクルージョン部分を予測するか、2つの例が同じ基礎となる画像の摂動バージョンであるかどうかを予測するようにモデルをトレーニングすることがあります。自己教師付きモデルは表現を学習することが多く、その後、関心のある下流のタスクで結果のモデルを微調整することによって活用されます。 

### 環境とのやりとり

これまで、データの実際の出所や、機械学習モデルが出力を生成するときに実際に何が起こるかについては説明していません。これは、教師あり学習と教師なし学習は、これらの問題に非常に洗練された方法で対処しないためです。いずれの場合も、大量のデータを事前に取得し、環境と相互作用することなくパターン認識マシンを動作させます。すべての学習はアルゴリズムが環境から切り離された後に行われるため、これは*オフライン学習*と呼ばれることもあります。たとえば、教師あり学習は :numref:`fig_data_collection` に示される単純な相互作用パターンを想定しています。 

![Collecting data for supervised learning from an environment.](../img/data-collection.svg)
:label:`fig_data_collection`

オフライン学習のこのシンプルさには魅力があります。利点は、動的な環境との相互作用から生じる複雑さを心配することなく、パターン認識を単独で心配できることです。しかし、この問題の定式化は制限されています。アシモフのロボット小説を読んで育ったなら、予測を行うだけでなく、世界で行動を起こすことができる人工知能エージェントを想像するかもしれません。予測モデルだけでなく、インテリジェントな*エージェント*について考えたいと考えています。つまり、単に予測をするのではなく、*アクション*を選択することを考える必要があるということです。単なる予測とは異なり、行動は実際に環境に影響を与えます。インテリジェントエージェントをトレーニングする場合、そのアクションがエージェントの将来の観察にどのように影響するかを説明する必要があります。 

環境との相互作用を考慮すると、一連の新しいモデリングの問題が生まれます。以下はほんの一例です。 

* 環境は私たちが以前にしたことを覚えていますか？
* 環境は私たちを助けたいと思っていますか？例えば、ユーザーが音声認識機能でテキストを読むような場合ですか？
* スパムフィルターを回避するためにメールを改ざんするスパマーなど、環境は私たちを打ち負かしたいですか？
* 環境のダイナミクスは変化していますか？たとえば、未来のデータは常に過去に似ているのか、それとも自然にパターンが時間とともに変化するのか、それとも自動化ツールに応じて変化するのか？

これらの質問は、トレーニングデータとテストデータが異なる*分布シフト*の問題を提起します。私たちのほとんどは、講師が書いた試験を受けるときにこの問題を経験しましたが、宿題はティーチングアシスタントによって構成されていました。次に、強化学習について簡単に説明します。強化学習は、エージェントが環境と対話する学習問題を提起するための豊富なフレームワークです。 

### 強化学習

機械学習を使用して、環境と相互作用し、行動を起こすエージェントを開発することに興味があるなら、おそらく*強化学習*に焦点を当てることになるでしょう。これには、ロボット工学、対話システム、さらにはビデオゲーム用の人工知能（AI）の開発への応用も含まれます。
*ディープ強化学習*、これが当てはまる
ディープラーニングから強化学習の問題まで、人気が急上昇しています。視覚入力のみを使用してアタリの試合で人間を打ち負かす画期的なディープQネットワーク:cite:`mnih2015human`と、ボードゲームGo :cite:`Silver.Huang.Maddison.ea.2016`で世界チャンピオンを倒したAlphaGoプログラムは、2つの顕著な例です。 

強化学習は、エージェントが一連の時間ステップにわたって環境と対話するという、非常に一般的な問題の説明を提供します。各タイムステップで、エージェントは環境から*観測*を受け取り、何らかのメカニズム（*アクチュエータ*と呼ばれることもあります）を介して環境に送信される*アクション*を選択する必要があります。最後に、エージェントは環境から報酬を受け取ります。このプロセスは:numref:`fig_rl-environment`に示されています。その後、エージェントは後続の観測値を受け取り、後続のアクションを選択します。強化学習エージェントの動作は、*ポリシー* によって管理されます。要するに、*ポリシー*は、環境の観察から行動にマップする単なる機能です。強化学習の目標は、良い政策を生み出すことです。 

![The interaction between reinforcement learning and an environment.](../img/rl-environment.svg)
:label:`fig_rl-environment`

強化学習の枠組みの一般性を誇張するのは難しい。たとえば、教師あり学習問題を強化学習問題としてキャストできます。分類の問題があったとしましょう。各クラスに対応する1つのアクションを持つ強化学習エージェントを作成できます。その後、元の教師あり学習問題からの損失関数とまったく等しい報酬を与える環境を作り出すことができました。 

とはいえ、強化学習は、教師あり学習ではできない多くの問題にも対処できます。たとえば、教師あり学習では、トレーニング入力が正しいラベルに関連付けられていることを常に期待しています。しかし、強化学習では、観察ごとに環境が最適な行動を教えてくれるとは想定していません。一般的に、私たちはいくらかの報酬を得るだけです。さらに、環境は、どの行動が報酬につながったかを教えてくれないかもしれません。 

チェスのゲームを考えてみましょう。唯一の本当の報酬シグナルは、ゲームの終わりに勝って報酬を獲得したとき、たとえば1の報酬を獲得したとき、または負けて、たとえば-1の報酬を受け取ったときに発生します。したがって、強化学習者は*クレジット割り当て*の問題に対処する必要があります。つまり、結果に対してどのアクションをクレジットするか、または非難するかを決定することです。10月11日に昇進した従業員についても同じことが言えます。そのプロモーションは、前年に比べて厳選された多数の行動を反映している可能性があります。今後、より多くのプロモーションを獲得するには、そのプロモーションにつながった途中でどのようなアクションがあったかを把握する必要があります。 

強化学習者は、部分的な可観測性の問題にも対処しなければならない場合があります。つまり、現在の観測では、現在の状態に関するすべてがわかるとは限りません。掃除ロボットが、家の中の同じクローゼットの中に閉じ込められているとしましょう。ロボットの正確な位置を推測するには、クローゼットに入る前に以前の観察結果を考慮する必要があるかもしれません。 

最後に、どの時点でも、強化学習者は1つの優れたポリシーを知っているかもしれませんが、エージェントが試したことのない優れたポリシーが他にもたくさんあるかもしれません。強化学習者は、（現在）最もよく知られている戦略を政策として*活用*するか、戦略の空間を*探求*し、知識と引き換えに短期的な報酬をあきらめる可能性があるかを常に選択する必要があります。 

一般的な強化学習の問題は、非常に一般的な設定です。アクションは後続の観測に影響します。報酬は、選択したアクションに対応する場合にのみ観察されます。環境は、完全にまたは部分的に観察されます。この複雑さを一度に説明すると、あまりにも多くの研究者に尋ねるかもしれません。さらに、すべての実際的な問題がこの複雑さをすべて示すわけではありません。その結果、研究者は強化学習の問題の特殊なケースをいくつか研究してきました。 

環境が完全に観察されると、強化学習問題を*マルコフ決定過程*と呼びます。国家が以前の行動に依存しない場合、私たちは問題を*文脈上の盗賊問題*と呼びます。状態がなく、最初は報酬が不明な一連の利用可能なアクションだけの場合、この問題は古典的な*マルチアームバンディット問題*です。 

## ルーツ

機械学習が対処できる問題のごく一部をレビューしました。ディープラーニングは、さまざまな機械学習の問題に対して、それらを解決するための強力なツールを提供します。多くのディープラーニング手法は最近の発明ですが、データからの学習の背後にある核となるアイデアは何世紀にもわたって研究されてきました。実際、人間は長い間、データを分析し、将来の結果を予測したいという欲求を抱いており、自然科学の多くはこれにルーツがあります。たとえば、ベルヌーイ分布は [Jacob Bernoulli (1655—1705)](https://en.wikipedia.org/wiki/Jacob_Bernoulli) にちなんで名付けられ、ガウス分布は [カール・フリードリヒ・ガウス (1777—1855)](https://en.wikipedia.org/wiki/Carl_Friedrich_Gauss) によって発見されました。たとえば、彼は最小平均二乗アルゴリズムを発明しました。このアルゴリズムは、保険の計算から医療診断まで、数え切れないほどの問題に今日でも使用されています。これらのツールは、自然科学における実験的アプローチを生み出しました。たとえば、抵抗器の電流と電圧に関するオームの法則は、線形モデルによって完全に記述されます。 

中世になっても、数学者は推定の鋭い直感を持っていました。たとえば、[Jacob Köbel (1460—1533)](https://www.maa.org/press/periodicals/convergence/mathematical-treasures-jacob-kobels-geometry) の幾何学の本は、人口の平均足の長さを推定するために、16人の成人男性の足の長さを平均化することを示しています (:numref:`fig_koebel`)。 

![Estimating the length of a foot.](../img/koebel.jpg)
:width:`500px`
:label:`fig_koebel`

個人のグループが教会を出ると、16人の成人男性が列に並んで足を測定するように求められました。次に、これらの測定値の合計を16で割って、現在の1フィートに相当する推定値を求めました。この「アルゴリズム」は、不格好な足に対処するために後で改善されました。最も短い足と最も長い足を持つ2人の男性が送り出され、残りの部分のみの平均化されました。これは、調整された平均推定の最も初期の例の1つです。 

統計は、データの収集と可用性によって本当に始まりました。その先駆者の一人である [ロナルド・フィッシャー（1890—1962）]（https://en.wikipedia.org/wiki/Ronald_Fisher）は、その理論と遺伝学への応用に大きく貢献しました。彼のアルゴリズム（線形判別分析など）と数式（フィッシャー情報行列など）の多くは、現代統計の基礎において依然として重要な位置を占めています。彼のデータリソースでさえも永続的な影響を与えました。Fisher が 1936 年にリリースした Iris データセットは、今でも機械学習アルゴリズムのデモンストレーションに使用されています。フィッシャーは優生学の支持者でもあり、道徳的に疑わしいデータサイエンスの使用は、産業や自然科学における生産的な使用と同じくらい長く永続的な歴史があることを思い出させるはずです。 

機械学習の 2 つ目の影響は、[クロード・シャノン (1916—2001)](https://en.wikipedia.org/wiki/Claude_Shannon) による情報理論と [アラン・チューリング (1912—1954)](https://en.wikipedia.org/wiki/Alan_Turing) を介した計算理論から来ました。チューリングは「機械は考えることができる？」という質問を投げかけました。彼の有名な論文*コンピューティング機械と知能* :cite:`Turing.1950`。彼がチューリングテストとして説明したように、人間の評価者がテキストによる相互作用に基づいて機械と人間からの応答を区別することが難しい場合、機械は「インテリジェント」と見なすことができます。 

別の影響は、神経科学と心理学に見られます。結局のところ、人間は明らかに知的な行動を示します。多くの学者は、この能力を説明し、場合によってはリバースエンジニアリングできるかどうかを尋ねてきました。生物学的にインスパイアされた最も古いアルゴリズムの1つは、[ドナルド・ヘブ（1904—1985）]（https://en.wikipedia.org/wiki/Donald_O._Hebb）によって策定されました。画期的な著書「行動の組織」（Organization of Behavior）:cite:`Hebb.Hebb.1949`で、彼はニューロンがポジティブな強化によって学習すると主張しました。これは、ヘビアン学習ルールとして知られるようになりました。これらのアイデアは、ローゼンブラットのパーセプトロン学習アルゴリズムのような後の作品に影響を与え、今日のディープラーニングを支える多くの確率的勾配降下アルゴリズムの基礎を築きました。望ましい動作を強化し、望ましくない動作を減らして、ニューラルネットワークのパラメーターの適切な設定を取得します。 

生物学的なインスピレーションは、*ニューラルネットワーク*に名前を付けたものです。1世紀以上にわたり（1873年のアレクサンダーベインと1890年のジェームズシェリントンのモデルにまでさかのぼる）、研究者は相互作用するニューロンのネットワークに似た計算回路を組み立てようとしました。時間が経つにつれて、生物学の解釈は文字通りではなくなってきましたが、名前は固執しました。その中心には、今日のほとんどのネットワークに見られるいくつかの重要な原則があります。 

* 線形処理単位と非線形処理単位を交互に組み合わせたもので、しばしば*レイヤー* と呼ばれます。
* ネットワーク全体のパラメータを一度に調整するためのチェーンルール (*バックプロパゲーション*とも呼ばれる) の使用。

初期の急速な進歩の後、ニューラルネットワークの研究は1995年頃から2005年まで衰退しました。これは主に2つの理由によるものです。まず、ネットワークのトレーニングは計算上非常に高価です。前世紀の終わりにはランダムアクセスメモリが豊富でしたが、計算能力は不足していました。第二に、データセットは比較的小さかった。実際、1932年のFisherのIrisデータセットは、アルゴリズムの有効性をテストするための人気のあるツールでした。60000の手書きの数字を持つMNISTデータセットは巨大と見なされました。 

データと計算が不足していることを考えると、カーネル手法、決定木、グラフィカルモデルなどの強力な統計ツールは、多くのアプリケーションで経験的に優れていることが証明されました。さらに、ニューラルネットワークとは異なり、トレーニングに何週間もかからず、強力な理論的保証で予測可能な結果を提供しました。 

## ディープラーニングへの道

この大部分は、World Wide Web、オンラインで何億人ものユーザーにサービスを提供する企業の出現、安価で高品質のセンサーの普及、安価なデータストレージ（Kryderの法則）、および安価な計算（ムーアの法則）により、大量のデータの可用性によって変化しました。特に、ディープラーニングにおける計算の状況は、もともとコンピューターゲーム用に設計されたGPUの進歩によって革命を起こしました。突然、計算上実行不可能と思われるアルゴリズムとモデルが関連するようになりました（逆もまた同様です）。これは:numref:`tab_intro_decade`で最もよく説明されています。 

:データセット vs. コンピュータメモリと計算能力 

|Decade|Dataset|Memory|Floating point calculations per second|
|:--|:-|:-|:-|
|1970|100 (Iris)|1 KB|100 KF (Intel 8080)|
|1980|1 K (house prices in Boston)|100 KB|1 MF (Intel 80186)|
|1990|10 K (optical character recognition)|10 MB|10 MF (Intel 80486)|
|2000|10 M (web pages)|100 MB|1 GF (Intel Core)|
|2010|10 G (advertising)|1 GB|1 TF (Nvidia C2050)|
|2020|1 T (social network)|100 GB|1 PF (Nvidia DGX-2)|
:label:`tab_intro_decade`

ランダムアクセスメモリは、データの増加に追いついていないことに注意してください。同時に、計算能力の向上は、データセットの増加を上回っています。これは、計算予算の増加により、統計モデルをよりメモリ効率にする必要があり、パラメーターを最適化するためにより多くのコンピューターサイクルを費やす必要があることを意味します。その結果、機械学習と統計学のスイートスポットは、（一般化された）線形モデルとカーネル手法からディープニューラルネットワークに移行しました。これは、多層パーセプトロン:cite:`McCulloch.Pitts.1943`、畳み込みニューラルネットワーク:cite:`LeCun.Bottou.Bengio.ea.1998`、長期短期記憶:cite:`Hochreiter.Schmidhuber.1997`、Qラーニング:cite:`Watkins.Dayan.1992`など、ディープラーニングの主力の多くが、比較的休眠状態になった後、過去10年間に本質的に「再発見」された理由の1つでもあります。かなりの時間。 

統計モデル、アプリケーション、アルゴリズムの最近の進歩は、種の進化の急速な進歩の瞬間であるカンブリア紀の爆発に例えられることがあります。実際、最先端技術は数十年前のアルゴリズムに適用された利用可能なリソースの単なる結果ではありません。以下のリストは、研究者が過去10年間で途方もない進歩を達成するのを助けてきたアイデアの表面をかろうじて傷つけていることに注意してください。 

* *dropout* :cite:`Srivastava.Hinton.Krizhevsky.ea.2014` などの新しい容量制御方法は、過適合の緩和に役立っています。ここでは、学習中にニューラルネットワーク全体にノイズが注入されます :cite:`Bishop.1995`。
* 注意メカニズムは、1世紀以上にわたって統計を悩ませてきた2つ目の問題を解決しました。学習可能なパラメータの数を増やすことなく、システムのメモリと複雑さをどのように増やすかです。研究者は、学習可能なポインター構造としてしか見ることができないものを使用して、洗練された解決策を見つけました :cite:`Bahdanau.Cho.Bengio.2014`。固定次元の表現での機械翻訳など、テキストシーケンス全体を覚える必要はなく、保存する必要があるのは翻訳プロセスの中間状態へのポインタだけでした。これにより、モデルは新しいシーケンスの生成を開始する前にシーケンス全体を記憶する必要がなくなったため、長いシーケンスの精度が大幅に向上しました。注意メカニズムのみに基づいて構築されたトランスアーキテクチャ :cite:`Vaswani.Shazeer.Parmar.ea.2017` は、幅広い分野で魅力的な成功を収めています。たとえば、テキスト、画像、関節トルク、ボタン押下などの多様なモダリティについて事前にトレーニングされた単一のトランスフォーマーは、Atari、キャプション画像、チャットを再生し、ロボットを制御できます :cite:`reed2022generalist`。
* メモリネットワーク:cite:`Sukhbaatar.Weston.Fergus.ea.2015`やニューラルプログラマインタプリタ:cite:`Reed.De-Freitas.2015`を介したマルチステージ設計により、統計モデラーは推論への反復アプローチを記述することができました。これらのツールを使用すると、ディープニューラルネットワークの内部状態を繰り返し変更できるため、プロセッサが計算のためにメモリを変更する方法と同様に、推論の連鎖で後続のステップを実行できます。
* もう1つの重要な開発は、敵対的生成ネットワーク:cite:`Goodfellow.Pouget-Abadie.Mirza.ea.2014`の発明でした。従来、密度推定と生成モデルの統計的手法は、適切な確率分布と、それらからサンプリングする（多くの場合近似）アルゴリズムを見つけることに重点を置いていました。その結果、これらのアルゴリズムは、統計モデルに固有の柔軟性の欠如によって大きく制限されていました。敵対的生成ネットワークにおける重要な革新は、サンプラーを微分可能なパラメーターを持つ任意のアルゴリズムに置き換えることでした。次に、ディスクリミネータ（事実上2サンプル検定）が偽物と実際のデータを区別できないように調整されます。任意のアルゴリズムを使用してデータを生成する機能により、密度推定がさまざまな手法に開かれました。疾走するシマウマ:cite:`Zhu.Park.Isola.ea.2017`の例と偽の有名人の顔:cite:`Karras.Aila.Laine.ea.2017`の例はどちらもこの進歩の証です。アマチュアの落書き者でも、シーンのレイアウトが:cite:`Park.Liu.Wang.ea.2019`のように見える様子を説明するスケッチだけに基づいて、フォトリアリスティックな画像を作成できます。
* 多くの場合、トレーニングに使用できる大量のデータを処理するには、単一の GPU では不十分です。過去10年間で、並列分散型トレーニングアルゴリズムを構築する能力は大幅に向上しました。スケーラブルなアルゴリズムを設計する際の重要な課題の1つは、ディープラーニング最適化の主力製品である確率的勾配降下法が、処理されるデータの比較的小さなミニバッチに依存していることです。同時に、小さなバッチはGPUの効率を制限します。したがって、ミニバッチサイズ、たとえばバッチあたり32個のイメージを持つ1024個のGPUでのトレーニングは、約32000個のイメージの集約ミニバッチになります。最近の研究では、最初は:citet:`Li.2017`、続いて:citet:`You.Gitman.Ginsburg.2017`と:citet:`Jia.Song.He.ea.2018`によってサイズが64000に押し上げられ、ImageNetデータセットでのResNet-50モデルのトレーニング時間が7分未満に短縮されました。比較のため、当初、トレーニング時間は日数順に測定されていました。
* 計算を並列化する能力は、強化学習の進歩にも貢献しています。これは、囲碁、アタリゲーム、スタークラフトなどのタスクや物理シミュレーション（例：MujoCOの使用）で超人的なパフォーマンスを達成するコンピューターの大きな進歩につながりました。利用可能。AlphaGoでこれを達成する方法の説明については、例えば:citet:`Silver.Huang.Maddison.ea.2016`を参照してください。一言で言えば、強化学習は、たくさんの (状態、アクション、報酬) タプルが利用できる場合に最も効果的です。シミュレーションはそのような道を提供します。
* ディープラーニングのフレームワークは、アイデアを広める上で重要な役割を果たしてきました。ニューラルネットワークモデリングのための第1世代のオープンソースフレームワークは、[Caffe](https://github.com/BVLC/caffe)、[Torch](https://github.com/torch)、および[Theano](https://github.com/Theano/Theano)で構成されていました。多くの独創的な論文は、これらのツールを使用して書かれました。現在では、[TensorFlow](https://github.com/tensorflow/tensorflow)（高レベルAPI [Keras](https://github.com/keras-team/keras)を介して使用されることが多い）、[CNTK](https://github.com/Microsoft/CNTK)、[Caffe 2](https://github.com/caffe2/caffe2)、および[Apache MXNet](https://github.com/apache/incubator-mxnet)に置き換えられています。第3世代のツールは、ディープラーニングのためのいわゆる*命令型*ツールで構成されています。この傾向は、モデルを記述するためにPython NumPyに似た構文を使用していた[Chainer](https://github.com/chainer/chainer)によって発火されたことは間違いありません。このアイデアは、[PyTorch](https://github.com/pytorch/pytorch)、MXNetの[Gluon API](https://github.com/apache/incubator-mxnet)、および[Jax](https://github.com/google/jax)の両方で採用されました。

より優れたツールを構築するシステム研究者とより優れたニューラルネットワークを構築する統計モデラーの間の分業は、物事を大幅に簡素化しました。たとえば、線形ロジスティック回帰モデルのトレーニングは、以前は自明ではない宿題の問題であり、2014年にカーネギーメロン大学の新しい機械学習博士課程の学生に与える価値があります。今では、このタスクは10行未満のコードで達成でき、プログラマーはしっかりと把握できます。 

## 成功事例

AIには、そうでなければ達成するのが難しい結果をもたらしてきた長い歴史があります。たとえば、光学式文字認識を使用する郵便物の仕分けシステムは、1990年代から導入されてきました。これは、結局のところ、手書きの数字の有名なMNISTデータセットのソースです。同じことが、銀行預金の小切手の読み取りと申請者の信用力のスコアリングにも当てはまります。金融取引は詐欺のチェックが自動的に行われます。これは、PayPal、Stripe、AliPay、WeChat、Apple、Visa、MasterCardなど、多くの電子商取引決済システムのバックボーンを形成しています。チェスのコンピュータープログラムは何十年もの間競争力があります。機械学習は、インターネット上での検索、推奨、パーソナライズ、ランキングを提供します。言い換えれば、機械学習は、しばしば目に見えないものの、普及しています。 

AIが脚光を浴びているのはごく最近のことであり、主に以前は扱いにくいと考えられていて、消費者に直接関係している問題の解決策が原因です。このような進歩の多くは、ディープラーニングによるものです。 

* AppleのSiri、AmazonのAlexa、Googleのアシスタントなどのインテリジェントアシスタントは、話された質問に妥当な精度で答えることができます。これには、電灯のスイッチをオンにするなどの簡単なタスクや、理髪店の予約の手配や電話サポートのダイアログの提供など、より複雑なタスクが含まれます。これは、AIが私たちの生活に影響を与えていることを示す最も顕著な兆候である可能性があります。
* デジタル・アシスタントの重要な要素は、音声を正確に認識する能力です。徐々に、このようなシステムの精度は、特定のアプリケーションで人間の同等性を達成するまでに向上しています :cite:`Xiong.Wu.Alleva.ea.2018`。
* 物体認識も同様に長い道のりを歩んできました。写真の中の物体を推定することは、2010年にはかなり困難な作業でした。ImageNetベンチマークでは、NECラボとイリノイ大学アーバナ・シャンペーン校の研究者がトップ5のエラー率 28% :cite:`Lin.Lv.Zhu.ea.2010`を達成しました。2017年までに、このエラー率は 2.25% :cite:`Hu.Shen.Sun.2018` に減少しました。同様に、鳥類の特定と皮膚がんの診断についても驚くべき結果が得られています。
* ゲームの腕前は、人間の知性の測定棒を提供するために使用されました。TD-Gammonをはじめ、時差強化学習、アルゴリズム、計算の進歩を使用してバックギャモンをプレイするプログラムは、幅広いアプリケーションのためのアルゴリズムにつながっています。バックギャモンとは異なり、チェスははるかに複雑な状態空間と一連のアクションを持っています。DeepBlueは、大規模な並列処理、特殊用途のハードウェア、およびゲームツリーを介した効率的な検索を使用して、Garry Kasparovを打ち負かしました :cite:`Campbell.Hoane-Jr.Hsu.2002`。Goは、その巨大な状態空間のため、さらに困難です。AlphaGoは、モンテカルロ木サンプリング:cite:`Silver.Huang.Maddison.ea.2016`と組み合わせたディープラーニングを使用して、2015年に人間の同等性を達成しました。ポーカーでの課題は、ステートスペースが大きく、部分的にしか観察されないことでした（対戦相手のカードはわかりません）。Libratusは、効率的に構造化された戦略を使用してポーカーで人間のパフォーマンスを上回りました :cite:`Brown.Sandholm.2017`。
* AIの進歩を示すもう1つの兆候は、自動運転車とトラックの出現です。完全な自律性は手の届かないところにありますが、テスラ、NVIDIA、Waymoなどの企業が少なくとも部分的な自律性を可能にする製品を出荷することで、この方向で大きな進歩が見られました。完全な自律性を非常に困難にしているのは、適切な運転には、認識し、推論し、システムにルールを組み込む能力が必要であるということです。現在、ディープラーニングは、主にこれらの問題のコンピュータービジョンの側面で使用されています。残りはエンジニアによって大幅に調整されています。

これは、機械学習のインパクトのあるアプリケーションの表面をほとんど傷つけません。たとえば、ロボット工学、ロジスティクス、計算生物学、素粒子物理学、天文学は、少なくとも部分的に機械学習による最近の最も印象的な進歩のいくつかを負っています。機械学習は、エンジニアや科学者にとってユビキタスなツールになりつつあります。 

AIに関する非技術的な記事で、来るべきAIの黙示録と*特異点*の妥当性についての質問が頻繁に提起されています。恐れているのは、機械学習システムが、人間の生活に直接影響を与えるプログラマーから独立して、感覚的になり、意思決定を下すことです。ある程度、AIはすでに人間の生活に直接的な影響を与えています。信用度は自動的に評価され、自動操縦は主に車両をナビゲートし、保釈を許可するかどうかの決定は統計データを入力として使用します。もっと軽薄に、Alexaにコーヒーマシンのスイッチを入れるように頼むことができます。 

幸いなことに、私たちは人間の作成者を故意に操作できる知覚力のあるAIシステムとはほど遠いです。まず、AIシステムは、特定の目標指向の方法で設計、トレーニング、および展開されます。彼らの行動は一般的な知性の錯覚を与えるかもしれませんが、設計の根底にあるのはルール、ヒューリスティック、統計モデルの組み合わせです。第二に、現在のところ、*人工知能*のためのツールは、自分自身を改善し、自分自身を推論し、一般的なタスクを解決しようとしながら独自のアーキテクチャを変更、拡張、改善することができる、単に存在しません。 

もっと差し迫った懸念は、私たちの日常生活でAIがどのように使用されているかです。トラック運転手や店員が実行する多くの面倒なタスクは自動化でき、自動化される可能性があります。農業用ロボットは有機農業のコストを削減する可能性が高いですが、収穫作業も自動化されます。トラック運転手や店員は多くの国で最も一般的な仕事の一部であるため、産業革命のこの段階は社会の広い範囲に深刻な影響を与える可能性があります。さらに、統計モデルを注意せずに適用すると、人種、性別、または年齢の偏見につながり、結果的な決定を推進するために自動化されている場合、手続きの公平性について合理的な懸念を引き起こす可能性があります。これらのアルゴリズムは注意して使用することが重要です。今日私たちが知っていることで、これは人類を破壊する悪意のあるスーパーインテリジェンスの可能性よりもはるかに差し迫った懸念を私たちに襲います。 

## ディープラーニングの本質

これまで、機械学習について幅広く説明してきました。ディープラーニングは、多層ニューラルネットワークに基づくモデルに関連する機械学習のサブセットです。そのモデルが変換の多くの*レイヤー*を学習するという意味で、正確には*深い*です。これは狭く聞こえるかもしれませんが、ディープラーニングは、目まぐるしい数のモデル、手法、問題の定式化、およびアプリケーションを生み出しました。深さの利点を説明するために、多くの直感が開発されました。間違いなく、すべての機械学習には多くの計算層があり、最初の層は特徴処理ステップで構成されます。ディープラーニングの違いは、表現の多くのレイヤーのそれぞれで学習された操作が、データから共同で学習されることです。 

生のオーディオ信号、画像の生のピクセル値からの学習、または任意の長さの文と外国語の対応する文の間のマッピングなど、これまでに説明した問題は、ディープラーニングが優れており、従来の方法がうまくいかない問題です。これらの多層モデルは、以前のツールではできなかった方法で低レベルの知覚データに対処できることがわかりました。おそらく、ディープラーニング手法で最も重要な共通点は、*エンドツーエンドのトレーニング*です。つまり、個別に調整されたコンポーネントに基づいてシステムを組み立てるのではなく、システムを構築し、そのパフォーマンスを共同で調整します。たとえば、コンピュータービジョンでは、科学者は機械学習モデルを構築するプロセスから*特徴量工学*のプロセスを分離していました。Cannyエッジ検出器:cite:`Canny.1987`とLoweのSIFT特徴抽出器:cite:`Lowe.2004`は、画像を特徴ベクトルにマッピングするアルゴリズムとして10年以上にわたって最高に君臨しました。昔、これらの問題に機械学習を適用する上で重要な部分は、データを浅いモデルに適した形式に変換する手動設計の方法を考え出すことでした。残念ながら、アルゴリズムによって自動的に実行される何百万もの選択肢に対する一貫した評価と比較して、人間が創意工夫によって達成できるものはほとんどありません。ディープラーニングが引き継がれると、これらの特徴抽出器は自動的に調整されたフィルターに置き換えられ、優れた精度が得られました。 

したがって、ディープラーニングの主な利点の1つは、従来の学習パイプラインの終わりにある浅いモデルだけでなく、労働集約的な特徴量エンジニアリングのプロセスにも取って代わることです。さらに、ディープラーニングは、ドメイン固有の前処理の多くを置き換えることで、以前はコンピュータービジョン、音声認識、自然言語処理、医療情報学、およびその他の応用分野を分離していた多くの境界を取り除き、多様性に取り組むための統一されたツールセットを提供しました問題。 

エンドツーエンドのトレーニングを超えて、パラメトリックな統計的記述から完全なノンパラメトリックモデルへの移行を経験しています。データが不足している場合、有用なモデルを得るためには、現実に関する仮定を単純化することに頼る必要があります。データが豊富な場合は、データにより適合するノンパラメトリックモデルに置き換えることができます。これは、前世紀半ばに物理学がコンピューターの利用可能性とともに経験した進歩をある程度反映しています。電子がどのように振る舞うかのパラメトリック近似を手で解くのではなく、関連する偏微分方程式の数値シミュレーションに頼ることができます。これにより、説明可能性が犠牲になることが多いものの、はるかに正確なモデルが作成されました。 

以前の研究とのもう1つの違いは、次善の解を受け入れること、非凸の非線形最適化問題を扱うこと、そしてそれらを証明する前に物事を試す意欲があることです。統計的問題への対処におけるこの新たに発見された経験主義と、才能の急速な流入が相まって、多くの場合、数十年にわたって存在していたツールの修正と再発明を犠牲にしても、実用的なアルゴリズムの急速な進歩につながりました。 

最終的に、ディープラーニングコミュニティは、学問や企業の境界を越えてツールを共有し、多くの優れたライブラリ、統計モデル、トレーニングされたネットワークをオープンソースとしてリリースすることに誇りを持っています。この精神のもと、この本を構成するノートブックは自由に配布および使用できます。私たちは、誰もがディープラーニングについて学ぶためのアクセスの障壁を下げるために懸命に取り組んできました。読者がこれから恩恵を受けることを願っています。 

## まとめ

機械学習は、コンピューターシステムがどのように経験 (多くの場合データ) を活用して特定のタスクでのパフォーマンスを向上させることができるかを研究します。統計、データマイニング、最適化のアイデアを組み合わせています。多くの場合、AIソリューションを実装する手段として使用されます。機械学習の一種として、表現学習は、データを表現する適切な方法を自動的に見つける方法に焦点を当てています。ディープラーニングは、変換の多くの層を学習することによるマルチレベルの表現学習として、従来の機械学習パイプラインの終わりにある浅いモデルだけでなく、労働集約的な特徴量エンジニアリングのプロセスにも取って代わります。ディープラーニングにおける最近の進歩の多くは、安価なセンサーやインターネット規模のアプリケーションから生じる豊富なデータと、主にGPUを介した計算の大幅な進歩によって引き起こされました。さらに、効率的なディープラーニングフレームワークが利用可能になったことで、システム全体の最適化の設計と実装が大幅に容易になりました。これは、高性能を得るための重要な要素です。 

## 演習

1. 現在書いているコードのどの部分を「学習」できるか、つまり、コードで行われる設計の選択を学習し、自動的に決定することによって改善できるでしょうか？あなたのコードにはヒューリスティックなデザインの選択肢が含まれていますか？目的の動作を学習するには、どのようなデータが必要ですか？
1. 解決方法の例はたくさんありますが、それらを自動化する具体的な方法がないのに、遭遇した問題はどれですか？これらは、ディープラーニングを使用する第一の候補となる可能性があります。
1. アルゴリズム、データ、計算の関係を説明する。データの特性と現在利用可能な計算リソースは、さまざまなアルゴリズムの妥当性にどのように影響しますか？
1. エンドツーエンドのトレーニングが現在デフォルトのアプローチではないが、役に立つかもしれない設定をいくつか挙げてください。

[Discussions](https://discuss.d2l.ai/t/22)
