# 環境と流通のシフト
:label:`sec_environment-and-distribution-shift`

前のセクションでは、さまざまなデータセットにモデルを適合させる機械学習の実践的なアプリケーションをいくつか取り上げました。それでも、そもそもデータがどこから来るのか、あるいはモデルからの出力で最終的に何をするつもりなのかを考えるのをやめませんでした。多くの場合、データを所有する機械学習の開発者は、これらの基本的な問題を検討するために立ち止まることなくモデルの開発に駆けつけます。 

失敗した機械学習の導入の多くは、このパターンにまでさかのぼることができます。テストセットの精度で測定すると、モデルは驚くほど機能しているように見えますが、データの分散が突然変化すると、展開時に壊滅的に失敗することがあります。もっと狡猾なことに、モデルの展開そのものがデータ配信を混乱させるきっかけになることがあります。たとえば、ローンの返済者と債務不履行を予測するモデルをトレーニングし、申請者の履物の選択が債務不履行のリスクに関連していることを発見したとします（オックスフォードは返済を示し、スニーカーは債務不履行を示します）。その後、オックスフォードを履いているすべての申請者にローンを与え、スニーカーを着用しているすべての申請者を拒否する傾向があるかもしれません。 

この場合、パターン認識から意思決定への私たちのよく考えられていない飛躍と、環境を批判的に考慮しなかったことは、悲惨な結果をもたらす可能性があります。手始めに、私たちが履物に基づいて決定を下し始めるとすぐに、顧客は自分の行動に追いつき、変化するでしょう。やがて、すべての応募者はオックスフォードを着用し、同時に信用力が向上することはありません。機械学習の多くのアプリケーションには同様の問題がたくさんあるので、少し時間をとってこれを要約してください。モデルベースの意思決定を環境に導入することで、モデルを壊す可能性があります。 

これらのトピックを1つのセクションで完全に扱うことはできませんが、ここでは、いくつかの共通の懸念を明らかにし、これらの状況を早期に検出し、損傷を軽減し、責任を持って機械学習を使用するために必要な批判的思考を刺激することを目指しています。解決策の中には単純な（「正しい」データを求める）ものもあれば、技術的に難しいもの（強化学習システムを実装する）ものや、統計的予測の領域から完全に外に出て、の倫理的適用に関する難しい哲学的問題に取り組む必要があるものもあります。アルゴリズム。 

## 流通シフトのタイプ

まず、データ分布が変化するさまざまな方法と、モデルのパフォーマンスを引き出すために何が行われるかを考慮して、パッシブ予測設定に固執します。ある古典的な設定では、トレーニングデータはあるディストリビューション $p_S(\mathbf{x},y)$ からサンプリングされたが、テストデータはいくつかの異なるディストリビューション $p_T(\mathbf{x},y)$ から抽出されたラベルのない例で構成されると仮定します。すでに、私たちは冷静な現実に立ち向かわなければなりません。$p_S$と$p_T$が互いにどのように関連しているかについての仮定がなければ、ロバストな分類器を学習することは不可能です。 

犬と猫を区別したい二項分類問題を考えてみましょう。分布が任意の方法でシフトできる場合、私たちのセットアップでは、入力に対する分布が一定である病理学的ケース（$p_S(\mathbf{x}) = p_T(\mathbf{x})$）を許可しますが、ラベルはすべて反転します：$p_S(y \mid \mathbf{x}) = 1 - p_T(y \mid \mathbf{x})$。言い換えれば、将来、すべての「猫」が犬になり、以前「犬」と呼ばれていたものが今では猫であると神が突然決定できるのであれば、入力値の分布を変えずに $p(\mathbf{x})$、この設定と分布がまったく変化しなかった設定とを区別することはできないでしょう。 

幸いなことに、私たちのデータが将来どのように変化するかについてのいくつかの制限された仮定の下で、原理アルゴリズムはシフトを検出し、時にはその場で適応することさえでき、元の分類器の精度を向上させることができます。 

### 共変量シフト

分布シフトのカテゴリーの中で、共変量シフトが最も広く研究されている可能性があります。ここでは、入力の分布は時間とともに変化する可能性がありますが、ラベル付け関数、つまり条件付き分布 $P(y \mid \mathbf{x})$ は変化しないと仮定します。統計学者は、共変量（特徴）の分布の変化によって問題が生じるため、これを*共変量シフト*と呼んでいます。因果関係を呼び出すことなく分布シフトについて推論できる場合もありますが、共変量シフトは、$\mathbf{x}$が$y$を引き起こすと私たちが信じる設定で呼び出す自然な仮定であることに注意してください。 

猫と犬を区別するという課題を考えてみましょう。私たちのトレーニングデータは、:numref:`fig_cat-dog-train`の種類の画像で構成されている可能性があります。 

![Training data for distinguishing cats and dogs.](../img/cat-dog-train.svg)
:label:`fig_cat-dog-train`

テスト時には、:numref:`fig_cat-dog-test`で画像を分類するように求められます。 

![Test data for distinguishing cats and dogs.](../img/cat-dog-test.svg)
:label:`fig_cat-dog-test`

トレーニングセットは写真で構成され、テストセットには漫画のみが含まれています。テストセットとは大幅に異なる特性を持つデータセットでトレーニングすると、新しいドメインにどのように適応するかについて一貫した計画がなければ、問題を引き起こす可能性があります。 

### ラベルシフト

*ラベルシフト* は、逆の問題を説明しています。
ここでは、ラベル限界$P(y)$は変更できるが、クラス条件付き分布$P(\mathbf{x} \mid y)$はドメイン間で固定されたままであると仮定します。ラベルシフトは、$y$が$\mathbf{x}$を引き起こすと私たちが信じるときに行うべき合理的な仮定です。たとえば、診断の相対的な有病率が時間とともに変化している場合でも、その症状（または他の症状）から診断を予測したい場合があります。病気は症状を引き起こすため、ここではラベルシフトが適切な仮定です。一部の縮退ケースでは、ラベルシフトと共変量シフトの仮定が同時に成り立ちます。たとえば、ラベルが決定論的である場合、$y$が$\mathbf{x}$の原因となる場合でも、共変量シフトの仮定は満たされます。興味深いことに、これらのケースでは、ラベルシフトの仮定から流れる方法で作業することがしばしば有利です。これは、これらの方法では、ディープラーニングで高次元になりがちな入力のように見えるオブジェクトとは対照的に、ラベルのように見えるオブジェクト（多くの場合低次元）を操作する傾向があるためです。 

### コンセプトシフト

また、ラベルの定義そのものが変わる可能性があるときに発生する、*コンセプトシフト*の関連問題にも遭遇する可能性があります。これは奇妙に聞こえます-*猫*は*猫*ですよね？ただし、他のカテゴリは、時間の経過とともに使用状況が変化する可能性があります。精神疾患の診断基準、ファッショナブルに合格するもの、および役職はすべて、かなりの量のコンセプトシフトの影響を受けます。:numref:`fig_popvssoda`に示すように、データのソースを地理的に移動して米国内を移動すると、*ソフトドリンク*の名前の分布に関する概念が大幅に変化することがわかります。 

![Concept shift on soft drink names in the United States.](../img/popvssoda.png)
:width:`400px`
:label:`fig_popvssoda`

機械翻訳システムを構築する場合、ディストリビューション $P(y \mid \mathbf{x})$ は場所によって異なる場合があります。この問題は見つけにくい場合があります。シフトは時間的または地理的な意味で徐々にしか起こらないという知識を活用したいと思うかもしれません。 

## 流通シフトの例

形式主義とアルゴリズムを掘り下げる前に、共変量や概念のシフトが明らかではないかもしれないいくつかの具体的な状況について議論することができます。 

### 医療診断

がんを検出するアルゴリズムを設計したいと想像してみてください。健康な人や病気の人からデータを収集し、アルゴリズムをトレーニングします。それはうまく機能し、高い精度を提供し、医療診断で成功するキャリアの準備ができていると結論付けます。
*そんなに早くない。*

トレーニングデータを生み出した分布と、実際に遭遇する分布は、かなり異なる可能性があります。これは、何年か前に私たち（作家）が一緒に働いていた不幸なスタートアップに起こりました。彼らは、主に高齢の男性に影響を与える病気の血液検査を開発しており、患者から収集した血液サンプルを使用してそれを研究することを望んでいました。しかし、すでにシステムに存在する病気の患者よりも、健康な男性から血液サンプルを入手することはかなり困難です。これを補うために、スタートアップは大学のキャンパスの学生からの献血を求めて、テストを開発する際の健康的なコントロールとして機能させました。次に、病気を検出するための分類器を構築するのを手伝うことができるかどうか尋ねました。 

私たちが彼らに説明したように、健康なコホートと病気のコホートをほぼ完璧な精度で区別するのは確かに簡単です。ただし、これは、被験者の年齢、ホルモンレベル、身体活動、食事、アルコール消費、および疾患とは無関係の多くの要因が異なるためです。これは実際の患者には当てはまりそうにありませんでした。サンプリング手順により、極端な共変量シフトが発生することが予想されます。さらに、このケースは従来の方法で修正できる可能性は低かった。要するに、彼らはかなりの金額を浪費した。 

### 自動運転車

ある会社が自動運転車の開発に機械学習を活用したいとしましょう。ここで重要なコンポーネントの1つは、路側検出器です。実際の注釈付きデータは入手に費用がかかるため、ゲームレンダリングエンジンからの合成データを追加のトレーニングデータとして使用する（賢明で疑わしい）アイデアがありました。これは、レンダリングエンジンから引き出された「テストデータ」に対して非常にうまく機能しました。ああ、実車の中では大惨事だった。結局のところ、道端は非常に単純なテクスチャでレンダリングされていました。さらに重要なのは、路側が*すべて*同じ*テクスチャでレンダリングされており、路側検出器がこの「特徴」について非常に迅速に学習したことです。 

米軍が森林内の戦車を最初に検出しようとしたときにも同様のことが起こりました。彼らはタンクなしで森の航空写真を撮り、次にタンクを森に運転して別の写真を撮りました。分類器は*完全に*機能しているように見えました。残念ながら、影のある木と影のない木を区別する方法を学んだだけでした。最初のセットは早朝に撮影され、2番目のセットは正午に撮影されました。 

### 非定常分布

分布がゆっくり変化し（*非定常分布*とも呼ばれる）、モデルが適切に更新されない場合は、さらに微妙な状況が発生します。以下は代表的なケースです。 

* 私たちは計算広告モデルを訓練し、それを頻繁に更新することに失敗します（例えば、iPadと呼ばれる不明瞭な新しいデバイスが発売されたばかりであることを組み込むのを忘れています）。
* スパムフィルターを構築します。これまでに見たすべてのスパムを検出するのに適しています。しかし、その後、スパマーは賢くなり、これまでに見たことのない新しいメッセージを作成します。
* 製品レコメンデーションシステムを構築します。冬の間は機能しますが、クリスマス後もずっとサンタ帽子を推奨し続けます。

### その他の逸話

* 顔検出器を構築します。すべてのベンチマークでうまく機能します。残念ながら、テストデータでは失敗します。問題のある例は、顔が画像全体を埋めるクローズアップです（トレーニングセットにはそのようなデータはありませんでした）。
* 米国市場向けのウェブ検索エンジンを構築し、英国で展開したいと考えています。
* 大規模なデータセットをコンパイルして画像分類器をトレーニングします。このデータセットでは、大規模なクラスのセットのそれぞれがデータセット内で等しく表され、1000個のカテゴリがそれぞれ1000個の画像で表されます。次に、写真の実際のラベル分布が明らかに不均一である現実世界にシステムを展開します。

## 流通シフトの修正

すでに説明したように、トレーニングとテストのディストリビューション $P(\mathbf{x}, y)$ が異なるケースが多くあります。場合によっては、共変量、ラベル、または概念のシフトにもかかわらず、ラッキーになり、モデルが機能することがあります。他のケースでは、シフトに対処するために原則的な戦略を採用することで、より良いことができます。このセクションの残りの部分は、かなり技術的なものになります。この資料は後続の概念の前提条件ではないため、せっかちな読者は次のセクションに進むことができます。 

### 経験的リスクとリスク
:label:`subsec_empirical-risk-and-risk`

まず、モデルトレーニング中に正確に何が起こっているのかを考えてみましょう。トレーニングデータ $\{(\mathbf{x}_1, y_1), \ldots, (\mathbf{x}_n, y_n)\}$ の特徴と関連するラベルを反復処理し、ミニバッチのたびにモデル $f$ のパラメーターを更新します。簡単にするために、正則化は考慮しないため、トレーニングの損失を大幅に最小限に抑えます。 

$$\mathop{\mathrm{minimize}}_f \frac{1}{n} \sum_{i=1}^n l(f(\mathbf{x}_i), y_i),$$
:eqlabel:`eq_empirical-risk-min`

ここで、$l$は、予測$f(\mathbf{x}_i)$に「どれほど悪い」かを測定する損失関数で、関連するラベル$y_i$が与えられます。統計学者は、:eqref:`eq_empirical-risk-min`の用語を*経験的リスク*と呼んでいます。*経験的リスク*は、*リスク*を概算するためのトレーニングデータの平均損失です。これは、真の分布$p(\mathbf{x},y)$から引き出されたデータの母集団全体に対する損失の予想値です。 

$$E_{p(\mathbf{x}, y)} [l(f(\mathbf{x}), y)] = \int\int l(f(\mathbf{x}), y) p(\mathbf{x}, y) \;d\mathbf{x}dy.$$
:eqlabel:`eq_true-risk`

しかし、実際には、通常、データの母集団全体を取得することはできません。したがって、:eqref:`eq_empirical-risk-min`の経験的リスクを最小化している*経験的リスク最小化*は、リスクをほぼ最小化することを期待して、機械学習の実用的な戦略です。 

### 共変量シフト補正
:label:`subsec_covariate-shift-correction`

データ$(\mathbf{x}_i, y_i)$とラベル付けした依存関係$P(y \mid \mathbf{x})$を推定すると仮定します。残念ながら、観測値$\mathbf{x}_i$は、*ターゲット分布* $p(\mathbf{x})$ではなく、いくつかの*ソース分布* $q(\mathbf{x})$から抽出されています。幸いなことに、依存関係の仮定は、条件付き分布が変化しないことを意味します:$p(y \mid \mathbf{x}) = q(y \mid \mathbf{x})$。ソースディストリビューション $q(\mathbf{x})$ が「間違っている」場合、リスクに次の単純な ID を使用することで修正できます。 

$$
\begin{aligned}
\int\int l(f(\mathbf{x}), y) p(y \mid \mathbf{x})p(\mathbf{x}) \;d\mathbf{x}dy =
\int\int l(f(\mathbf{x}), y) q(y \mid \mathbf{x})q(\mathbf{x})\frac{p(\mathbf{x})}{q(\mathbf{x})} \;d\mathbf{x}dy.
\end{aligned}
$$

言い換えれば、正しい分布から導き出される確率と間違った分布から導き出された確率の比率によって、各データ例を再重み付けする必要があります。 

$$\beta_i \stackrel{\mathrm{def}}{=} \frac{p(\mathbf{x}_i)}{q(\mathbf{x}_i)}.$$

各データ例$(\mathbf{x}_i, y_i)$の重み$\beta_i$を接続すると、以下を使用してモデルをトレーニングできます。
*加重経験的リスク最小化*:

$$\mathop{\mathrm{minimize}}_f \frac{1}{n} \sum_{i=1}^n \beta_i l(f(\mathbf{x}_i), y_i).$$
:eqlabel:`eq_weighted-empirical-risk-min`

ああ、その比率はわからないので、何か役に立つ前に見積もる必要があります。最小ノルムまたは最大エントロピー原理を使用して期待演算子を直接再調整しようとするいくつかの派手な演算子理論的アプローチなど、多くの方法が利用可能です。このようなアプローチでは、テストデータへのアクセスなどによる「真の」$p$と、トレーニングセット$q$の生成に使用されるもの（後者は簡単に利用可能）の両方のディストリビューションから抽出されたサンプルが必要であることに注意してください。ただし、必要なのは機能 $\mathbf{x} \sim p(\mathbf{x})$ だけであり、ラベル $y \sim p(y)$ にアクセスする必要はありません。 

この場合、元のものとほぼ同じくらい良い結果が得られる非常に効果的なアプローチがあります。ロジスティック回帰は、バイナリ分類のためのソフトマックス回帰（:numref:`sec_softmax`を参照）の特殊なケースです。推定確率比を計算するために必要なのはこれだけです。$p(\mathbf{x})$から抽出されたデータと$q(\mathbf{x})$から抽出されたデータを区別するための分類器を学習します。2 つのディストリビューションを区別できない場合は、関連付けられたインスタンスが 2 つのディストリビューションのどちらか一方から来る可能性が等しくなることを意味します。一方、適切に識別できるインスタンスは、それに応じて大幅にオーバーウェイトまたはアンダーウェイトする必要があります。 

簡単にするために、ディストリビューション $p(\mathbf{x})$ と $q(\mathbf{x})$ の両方からそれぞれ同じ数のインスタンスがあると仮定します。ここで、$z$ ラベルで表します。このラベルは、$p$ から抽出されたデータでは $1$、$q$ から抽出されたデータでは $-1$ になります。次に、混合データセットの確率は次の式で与えられます。 

$$P(z=1 \mid \mathbf{x}) = \frac{p(\mathbf{x})}{p(\mathbf{x})+q(\mathbf{x})} \text{ and hence } \frac{P(z=1 \mid \mathbf{x})}{P(z=-1 \mid \mathbf{x})} = \frac{p(\mathbf{x})}{q(\mathbf{x})}.$$

したがって、$P(z=1 \mid \mathbf{x})=\frac{1}{1+\exp(-h(\mathbf{x}))}$（$h$ はパラメーター化された関数）のロジスティック回帰アプローチを使用すると、次のようになります。 

$$
\beta_i = \frac{1/(1 + \exp(-h(\mathbf{x}_i)))}{\exp(-h(\mathbf{x}_i))/(1 + \exp(-h(\mathbf{x}_i)))} = \exp(h(\mathbf{x}_i)).
$$

その結果、2つの問題を解決する必要があります。1つ目は両方の分布から抽出されたデータを区別し、次に:eqref:`eq_weighted-empirical-risk-min`の重み付けされた経験的リスク最小化問題で、$\beta_i$で項を重み付けします。 

これで、補正アルゴリズムについて説明する準備が整いました。トレーニングセット $\{(\mathbf{x}_1, y_1), \ldots, (\mathbf{x}_n, y_n)\}$ とラベルのないテストセット $\{\mathbf{u}_1, \ldots, \mathbf{u}_m\}$ があるとします。共変量シフトでは、すべての$1 \leq i \leq n$の$\mathbf{x}_i$が何らかのソース分布から抽出され、すべての$1 \leq i \leq m$の$\mathbf{u}_i$がターゲット分布から抽出されると仮定します。共変量シフトを補正するための典型的なアルゴリズムは次のとおりです。 

1. 二項分類トレーニングセット $\{(\mathbf{x}_1, -1), \ldots, (\mathbf{x}_n, -1), (\mathbf{u}_1, 1), \ldots, (\mathbf{u}_m, 1)\}$ を生成します。
1. ロジスティック回帰を使用してバイナリ分類器に学習をさせ、関数 $h$ を取得します。
1. いくつかの定数 $c$ に対して $\beta_i = \exp(h(\mathbf{x}_i))$ またはそれ以上 $\beta_i = \min(\exp(h(\mathbf{x}_i)), c)$ を使用してトレーニングデータを重み付けします。
1. :eqref:`eq_weighted-empirical-risk-min`の$\{(\mathbf{x}_1, y_1), \ldots, (\mathbf{x}_n, y_n)\}$のトレーニングには、ウェイト$\beta_i$を使用してください。

上記のアルゴリズムは重要な仮定に依存していることに注意してください。このスキームが機能するためには、ターゲット (テスト時間など) 分布の各データ例が、学習時にゼロ以外の確率で発生する必要があります。$p(\mathbf{x}) > 0$で$q(\mathbf{x}) = 0$の点が見つかった場合、対応する重要度の重みは無限大になるはずです。 

### ラベルシフト補正

$k$ カテゴリの分類タスクを扱っていると仮定します。:numref:`subsec_covariate-shift-correction`で同じ表記法を使用すると、$q$と$p$はそれぞれソース分布（トレーニング時間など）とターゲット分布（テスト時間など）です。ラベルの分布が時間とともにシフトすると仮定します:$q(y) \neq p(y)$。しかし、クラス条件付き分布は同じ $q(\mathbf{x} \mid y)=p(\mathbf{x} \mid y)$ のままです。ソースディストリビューション $q(y)$ が「間違っている」場合、:eqref:`eq_true-risk` で定義されているリスクの次のアイデンティティに従って修正できます。 

$$
\begin{aligned}
\int\int l(f(\mathbf{x}), y) p(\mathbf{x} \mid y)p(y) \;d\mathbf{x}dy =
\int\int l(f(\mathbf{x}), y) q(\mathbf{x} \mid y)q(y)\frac{p(y)}{q(y)} \;d\mathbf{x}dy.
\end{aligned}
$$

ここで、重要度の重みはラベルの尤度比に対応します 

$$\beta_i \stackrel{\mathrm{def}}{=} \frac{p(y_i)}{q(y_i)}.$$

ラベルシフトの良い点の1つは、ソースディストリビューションにかなり良いモデルがあれば、周囲の次元に対処する必要なく、これらの重みの一貫した推定値を得ることができるということです。ディープラーニングでは、入力は画像のような高次元のオブジェクトになりがちですが、ラベルはカテゴリのような単純なオブジェクトであることがよくあります。 

ターゲットラベルの分布を推定するには、まず適度に優れた既製の分類器（通常はトレーニングデータでトレーニング済み）を使用し、検証セット（トレーニング分布からも）を使用して混同行列を計算します。*混同行列*、$\mathbf{C}$ は単に $k \times k$ 行列で、各列はラベルカテゴリ (グラウンドトゥルース) に対応し、各行はモデルの予測カテゴリに対応します。各セルの値 $c_{ij}$ は、真のラベルが $j$ で、モデルが予測した $i$ の検証セットの予測合計に対する割合です。 

複雑なリアルタイムアノテーションパイプラインに投資しない限り、実際に見られる例のラベルを見ることができないため、ターゲットデータの混同行列を直接計算することはできません。ただし、実行できることは、テスト時にすべてのモデル予測を平均して、平均モデル出力$\mu(\hat{\mathbf{y}}) \in \mathbb{R}^k$を算出することです。$i^\mathrm{th}$の要素$\mu(\hat{y}_i)$は、モデルが$i$を予測したテストセットの予測合計に対する割合です。 

ある穏やかな条件下では、分類器がそもそも合理的に正確であり、ターゲットデータに以前に見たカテゴリのみが含まれていて、ラベルシフトの仮定がそもそも当てはまる場合（ここでは最も強い仮定）、テストセットのラベルを推定できます。単純な線形システムを解くことによる分布 

$$\mathbf{C} p(\mathbf{y}) = \mu(\hat{\mathbf{y}}),$$

推定値として、$\sum_{j=1}^k c_{ij} p(y_j) = \mu(\hat{y}_i)$ はすべての $1 \leq i \leq k$ に当てはまるため、$p(y_j)$ は $k$ 次元のラベル分布ベクトル $p(\mathbf{y})$ の $j^\mathrm{th}$ 要素です。分類器が最初から十分正確であれば、混同行列 $\mathbf{C}$ は可逆になり、解が得られます $p(\mathbf{y}) = \mathbf{C}^{-1} \mu(\hat{\mathbf{y}})$。 

ソースデータのラベルを観察するため、分布$q(y)$を推定するのは簡単です。次に、ラベル$y_i$のトレーニング例$i$について、推定$p(y_i)/q(y_i)$の比率を使用して重み$\beta_i$を計算し、これを:eqref:`eq_weighted-empirical-risk-min`の加重経験的リスク最小化にプラグインできます。 

### コンセプトシフト修正

コンセプトシフトは、原則的に修正するのがはるかに困難です。たとえば、猫と犬を区別することから、白と黒の動物を区別する問題に突然問題が変わる状況では、新しいラベルを集めてゼロから訓練するよりもはるかに良いことができると考えるのは無理でしょう。幸いなことに、実際には、このような極端なシフトはまれです。代わりに、通常起こるのは、タスクがゆっくりと変化し続けることです。より具体的にするために、いくつかの例を挙げます。 

* コンピュテーショナル広告では、新製品が発売され、
古い製品はあまり人気がなくなります。これは、広告の分布とその人気が徐々に変化し、クリック率の予測因子もそれに伴って徐々に変化する必要があることを意味します。
* 交通カメラのレンズは、環境摩耗により徐々に劣化し、画質に次第に影響を与えます。
* ニュースコンテンツは徐々に変化します（つまり、ほとんどのニュースは変更されませんが、新しいストーリーが表示されます）。

このような場合、ネットワークのトレーニングに使用したのと同じアプローチを使用して、データの変化に適応させることができます。言い換えれば、ゼロからトレーニングするのではなく、既存のネットワークの重みを使用し、新しいデータでいくつかの更新ステップを実行するだけです。 

## 学習問題の分類

分布の変化にどう対処するかについての知識を身につけて、機械学習の問題定式化のいくつかの他の側面について考えることができるようになりました。 

### バッチ学習

*バッチ学習* では、モデル $f(\mathbf{x})$ のトレーニングに使用するトレーニング機能とラベル $\{(\mathbf{x}_1, y_1), \ldots, (\mathbf{x}_n, y_n)\}$ にアクセスできます。その後、このモデルを展開して、同じ分布から抽出された新しいデータ $(\mathbf{x}, y)$ をスコアリングします。これは、ここで説明する問題の既定の前提です。たとえば、たくさんの猫と犬の画像に基づいて猫検出器を訓練するかもしれません。一度トレーニングしたら、猫だけが入ることができるスマートキャットドアコンピュータービジョンシステムの一部として出荷します。これは顧客の家に設置され、（極端な状況を除いて）二度と更新されません。 

### オンライン学習

ここで、データ$(\mathbf{x}_i, y_i)$が一度に1つのサンプルに到達すると想像してください。具体的には、最初に$\mathbf{x}_i$を観察すると仮定し、次に推定$f(\mathbf{x}_i)$を考え出す必要があります。これを実行すると、$y_i$を観察し、決定に基づいて報酬を受け取るか損失を被ります。多くの実際の問題がこのカテゴリに分類されます。たとえば、明日の株価を予測する必要があります。これにより、その見積もりに基づいて取引することができ、一日の終わりに、見積もりで利益を上げることができるかどうかがわかります。言い換えれば、*オンライン学習*では、新しい観察を受けてモデルを継続的に改善する次のサイクルがあります。 

$$
\mathrm{model} ~ f_t \longrightarrow
\mathrm{data} ~ \mathbf{x}_t \longrightarrow
\mathrm{estimate} ~ f_t(\mathbf{x}_t) \longrightarrow
\mathrm{observation} ~ y_t \longrightarrow
\mathrm{loss} ~ l(y_t, f_t(\mathbf{x}_t)) \longrightarrow
\mathrm{model} ~ f_{t+1}
$$

### 盗賊

*Bandits* は上記の問題の特殊なケースです。ほとんどの学習問題には連続的にパラメータ化された関数$f$があり、そのパラメータ（深いネットワークなど）を学習しますが、*バンディット*問題では、引っ張ることができる腕の数が限られています。つまり、実行できるアクションの数は有限です。この単純な問題に対して、最適性の観点からより強力な理論的保証が得られることはそれほど驚くべきことではありません。この問題はしばしば（混乱を招く）別個の学習環境であるかのように扱われるため、主に挙げています。

### コントロール

多くの場合、環境は私たちがしたことを覚えています。必ずしも敵対的なやり方ではありませんが、それはただ覚えているだけで、その反応は以前に起こったことに依存します。たとえば、コーヒーボイラーコントローラーは、以前にボイラーを加熱していたかどうかによって、異なる温度を観察します。PID (比例-積分-微分) コントローラーアルゴリズムは一般的な選択肢です。同様に、ニュースサイトでのユーザーの行動は、私たちが以前に見せたものに依存します（例えば、彼はほとんどのニュースを一度だけ読むでしょう）。そのようなアルゴリズムの多くは、決定をランダムに見えないようにするなど、動作する環境のモデルを形成します。最近では、制御理論（PIDバリアントなど）もハイパーパラメータを自動的に調整して、より優れた解きほぐしと再構成の品質を達成し、生成テキストの多様性と生成された画像の再構成品質を改善するために使用されています :cite:`Shao.Yao.Sun.ea.2020`。 

### 強化学習

メモリのある環境のより一般的なケースでは、環境が私たちと協力しようとしている状況（特に非ゼロサムゲームの協力ゲーム）、または環境が勝とうとする他の状況に遭遇する可能性があります。チェス、ゴー、バックギャモン、スタークラフトは、*強化学習*のケースの一部です。同様に、自動運転車用の優れたコントローラーを構築したいと思うかもしれません。他の車は、回避しようとする、事故を起こそうとする、協力しようとするなど、自明ではない方法で自動運転車の運転スタイルに反応する可能性が高い。 

### 環境を考える

上記のさまざまな状況の主な違いの1つは、定常環境の場合に全体的に機能していたのと同じ戦略が、環境が適応できる場合は全体を通して機能しない可能性があることです。たとえば、トレーダーが発見したアービトラージの機会は、トレーダーがそれを悪用し始めると消滅する可能性があります。環境が変化する速度と方法によって、私たちが耐えることができるアルゴリズムのタイプが大きく決まります。例えば、物事がゆっくりとしか変化しないかもしれないとわかっているなら、どんな見積もりもゆっくりしか変えないように強制することができます。環境が瞬時に変化するかもしれないが、ごくまれにしか変化しないとわかっているなら、それを考慮に入れることができます。これらの種類の知識は、データサイエンティストがコンセプトシフト、つまり解決しようとしている問題が時間とともに変化するときに対処するために不可欠です。 

## 機械学習における公平性、説明責任、透明性

最後に、機械学習システムを展開するときは、単に予測モデルを最適化するだけでなく、通常、意思決定を（部分的または完全に）自動化するために使用されるツールを提供していることを覚えておくことが重要です。これらの技術システムは、結果として生じる決定の対象となる個人の生活に影響を与える可能性があります。予測の検討から意思決定への飛躍は、新しい技術的な問題だけでなく、慎重に検討しなければならない多くの倫理的問題も提起します。医療診断システムを導入する場合、どの集団に対して機能し、どの集団で機能しないかを知る必要があります。亜集団の福祉に対する予見可能なリスクを見落とすと、私たちは劣ったケアを行う可能性があります。さらに、意思決定システムを検討したら、一歩下がって、テクノロジーの評価方法を再考する必要があります。この範囲の変更による他の結果の中でも、*正確さ*が正しい尺度になることはめったにないことがわかります。たとえば、予測を行動に変換する場合、誤りの潜在的なコスト感度をさまざまな方法で考慮したいことがよくあります。画像を誤分類する1つの方法が人種的な手品として認識され、別のカテゴリへの誤分類が無害である場合、意思決定プロトコルの設計における社会的価値を考慮して、それに応じてしきい値を調整したい場合があります。また、予測システムがどのようにフィードバックループにつながるかについても注意する必要があります。たとえば、犯罪の予測が高い地域に巡回担当者を割り当てる予測警察システムを考えてみましょう。心配なパターンがどのように現れるかは簡単にわかります。 

 1. 犯罪が多い地域では、より多くのパトロールが行われます。
 1. その結果、これらの近傍でより多くの犯罪が発見され、将来の反復に利用可能なトレーニングデータが入力されます。
 1. より多くのポジティブにさらされるこのモデルは、これらの地域でさらに多くの犯罪を予測しています。
 1. 次のイテレーションでは、更新されたモデルが同じ近隣地域をさらにターゲットにし、さらに多くの犯罪が発見されるなどにつながります。

多くの場合、モデルの予測がトレーニングデータに結合されるさまざまなメカニズムは、モデリングプロセスでは考慮されません。これは、研究者が*暴走フィードバックループ*と呼ぶものにつながる可能性があります。さらに、そもそも正しい問題に取り組んでいるかどうかにも注意する必要があります。予測アルゴリズムは現在、情報の普及を媒介する上で非常に大きな役割を果たしています。個人が遭遇するニュースは、その人が*いいね！した*一連のFacebookページによって決定されるべきですか？これらは、機械学習のキャリアで遭遇する可能性のある、差し迫った倫理的ジレンマのほんの一部です。 

## まとめ

* 多くの場合、トレーニングセットとテストセットは同じディストリビューションから取得されません。これを分配シフトと呼びます。
* リスクとは、真の分布から引き出されたデータの母集団全体にわたる損失の予想です。ただし、この全人口は通常利用できません。経験的リスクとは、リスクを概算するためのトレーニングデータの平均損失です。実際には、経験的なリスク最小化を実行します。
* 対応する仮定の下で、共変量とラベルシフトはテスト時に検出および修正できます。この偏りを考慮しないと、テスト時に問題になる可能性があります。
* 場合によっては、環境が自動化されたアクションを記憶し、意外な方法で応答することがあります。モデルを構築する際にはこの可能性を考慮し、モデルと環境が予期せぬ形で絡み合う可能性に心を開いて、ライブシステムを監視し続ける必要があります。

## 演習

1. 検索エンジンの動作を変えるとどうなるでしょうか？ユーザーは何をしますか？広告主はどうですか？
1. 共変量シフト検出器を実装します。ヒント:分類器を構築する。
1. 共変量シフト補正器を実装します。
1. 分布シフト以外に、経験的リスクがリスクに近づく方法に影響を与える可能性があるのは他にありますか？

[Discussions](https://discuss.d2l.ai/t/105)
