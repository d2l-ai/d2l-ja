# サーバーと GPU の選択
:label:`sec_buy_gpu`

ディープラーニングのトレーニングには通常、大量の計算が必要です。現在、GPUはディープラーニングのための最も費用対効果の高いハードウェアアクセラレータです。特に、CPUと比較して、GPUは安価で、多くの場合、桁違いに高いパフォーマンスを提供します。さらに、1 台のサーバーで複数の GPU をサポートでき、ハイエンドサーバーでは最大 8 つの GPU をサポートできます。熱、冷却、および電力の要件は、オフィスビルがサポートできる範囲を超えて急速にエスカレートするため、より一般的な数値はエンジニアリングワークステーションでは最大4GPUです。大規模なデプロイメントでは、クラウドコンピューティング (例:Amazonの[P3](https://aws.amazon.com/ec2/instance-types/p3/)および[G4](https://aws.amazon.com/blogs/aws/in-the-works-ec2-instances-g4-with-nvidia-t4-gpus/)インスタンス) の方がはるかに実用的なソリューションです。 

## サーバーの選択

通常、計算の多くはGPUで行われるため、多くのスレッドを備えたハイエンドCPUを購入する必要はありません。とはいえ、Pythonのグローバルインタプリタロック（GIL）により、4〜8個のGPUがある状況では、CPUのシングルスレッドパフォーマンスが問題になる可能性があります。すべてが等しいということは、コアの数は少ないがクロック周波数が高いCPUの方が経済的な選択肢になる可能性があることを示唆しています。たとえば、6コア4GHzと8コア3.5 GHzのCPUを選択する場合、総速度は低いですが、前者の方がはるかに好ましいです。重要な考慮事項は、GPUは大量の電力を消費するため、大量の熱を放散することです。これには、非常に優れた冷却と、GPU を使用するのに十分な大きさのシャーシが必要です。可能であれば、以下のガイドラインに従ってください。 

1. **電源**。GPU は大量の電力を消費します。デバイスあたり最大350Wの予算（効率的なコードでは多くのエネルギーを使用する可能性があるため、通常の需要ではなく、グラフィックカードの*ピーク需要*を確認してください）。電力供給が需要に応えられないと、システムが不安定になることがあります。
1. **シャーシの大きさ**。GPU は大きく、補助電源コネクタには追加のスペースが必要になることがよくあります。また、大きなシャーシは冷却が容易です。
1. **GPU 冷却**。GPUが多数ある場合は、水冷に投資したいと思うかもしれません。また、ファン数が少ない場合でも*リファレンスデザイン*を目指してください。これは、デバイス間の空気を取り込むのに十分な薄さだからです。マルチファンGPUを購入した場合、複数のGPUを取り付けるときに十分な空気を得るには厚すぎる可能性があり、サーマルスロットリングが発生します。
1. **PCIe スロット**。GPU との間でデータを移動する (および GPU 間でデータを交換する) には、大量の帯域幅が必要です。16 レーンの PCIe 3.0 スロットをお勧めします。複数の GPU をマウントする場合は、マザーボードの説明をよく読んで、複数の GPU を同時に使用しても 16$\times$ の帯域幅が使用可能であること、および追加スロットに PCIe 2.0 ではなく PCIe 3.0 が使用されていることを確認してください。一部のマザーボードは、複数のGPUがインストールされていると、8$\times$または4$\times$の帯域幅にダウングレードされます。これは、CPU が提供する PCIe レーンの数に一部起因しています。

要するに、ディープラーニングサーバーを構築するための推奨事項をいくつか紹介します。 

* **初心者**。低消費電力のローエンドGPUを購入する（ディープラーニングに適した安価なゲーミングGPUは150〜200Wを使用）。運が良ければ、現在のコンピューターでサポートされます。
* **1 GPU**。4コアのローエンドCPUで十分で、ほとんどのマザーボードで十分です。32 GB 以上の DRAM を目指し、ローカルデータアクセス用の SSD に投資します。600Wの電源で十分です。たくさんのファンがいるGPUを購入しましょう。
* **2 GPU**。4～6 コアのローエンド CPU で十分です。64 GB DRAMを目指して、SSDに投資しましょう。2つのハイエンドGPUには1000Wのオーダーが必要です。メインボードに関しては、PCIe 3.0 x16 スロットが 2 つあることを確認してください。可能であれば、PCIe 3.0 x16スロットの間に2つの空きスペース（60mm間隔）があるメインボードを入手して、余分な空気を確保してください。この場合は、ファンの多いGPUを2つ購入してください。
* **4 GPU**。シングルスレッド速度が比較的速い（つまり、クロック周波数が高い）CPUを購入するようにしてください。おそらく、AMD Threadripperなど、より多くのPCIeレーンを搭載したCPUが必要になるでしょう。PCIeレーンを多重化するにはおそらくPLXが必要なため、4つのPCIe 3.0 x16スロットを入手するには比較的高価なメインボードが必要になるでしょう。狭く、GPU間に空気を入れるリファレンスデザインのGPUを購入します。1600 ～ 2000 W の電源装置が必要ですが、オフィスのコンセントではサポートされていない可能性があります。このサーバーはおそらく*大音量でホット*で動作します。机の下に置いてはいけません。128 GB の DRAM が推奨されます。ローカルストレージ用の SSD (1 ～ 2 TB NVMe) と、データを保存するための RAID 構成の多数のハードディスクを入手してください。
* **8 GPU **。複数の冗長電源を備えた専用のマルチ GPU サーバーシャーシを購入する必要があります (例:電源装置あたり 1600 W で 2+1)。これには、デュアルソケットサーバーCPU、256 GB ECC DRAM、高速ネットワークカード（10 GBE 推奨）が必要であり、サーバーがGPUの*物理フォームファクタ*をサポートしているかどうかを確認する必要があります。エアフローと配線の配置は、コンシューマとサーバーの GPU で大きく異なります (RTX 2080 と Tesla V100 など)。これは、電源ケーブルのスペースが不十分であるか、適切なワイヤーハーネスがないために（共著者の1人が痛々しいほど発見したように）、コンシューマーGPUをサーバーにインストールできない可能性があることを意味します。

## GPU を選択する

現在、AMDとNVIDIAは専用GPUの2つの主要メーカーです。NVIDIA はディープラーニング分野に初めて参入し、CUDA を介してディープラーニングフレームワークのサポートを強化しました。したがって、ほとんどの購入者はNVIDIA GPUを選択します。 

NVIDIA は、個人ユーザー (GTX および RTX シリーズなど) とエンタープライズユーザー (Tesla シリーズ経由) を対象とする 2 種類の GPU を提供しています。この 2 種類の GPU は、同等の処理能力を提供します。ただし、エンタープライズユーザーGPUは通常、（パッシブ）強制冷却、より多くのメモリ、およびECC（エラー修正）メモリを使用します。これらのGPUはデータセンターに適しており、通常はコンシューマーGPUの10倍のコストがかかります。 

100台以上のサーバーを持つ大企業の場合は、NVIDIA Teslaシリーズを検討するか、クラウドでGPUサーバーを使用する必要があります。ラボや 10 台以上のサーバーを持つ中小企業では、NVIDIA RTX シリーズが最も費用対効果が高いと思われます。4～8個のGPUを効率的に保持するSupermicroまたはAsusシャーシを備えた事前構成済みサーバーを購入できます。 

GPUベンダーは通常、2017年にリリースされたGTX 1000（Pascal）シリーズや2019年にリリースされたRTX 2000（Turing）シリーズなど、1〜2年ごとに新しい世代をリリースします。各シリーズには、異なるパフォーマンスレベルを提供するいくつかの異なるモデルがあります。GPU のパフォーマンスは、主に次の 3 つのパラメーターの組み合わせです。 

1. **計算能力**。一般的に、32ビット浮動小数点演算能力を求めています。16ビット浮動小数点トレーニング（FP16）も主流になりつつあります。予測だけに関心がある場合は、8 ビット整数を使用することもできます。最新世代のチューリングGPUは、4ビットアクセラレーションを提供します。残念ながら、現在、低精度のネットワークを学習させるアルゴリズムはまだ普及していません。
1. **メモリサイズ**。モデルが大きくなったり、トレーニング中に使用されるバッチが大きくなったりすると、より多くの GPU メモリが必要になります。HBM2 (高帯域幅メモリ) と GDDR6 (グラフィックス DDR) メモリを確認します。HBM2は高速ですが、はるかに高価です。
1. **メモリ帯域幅**。十分なメモリ帯域幅がある場合にのみ、コンピューティング能力を最大限に活用できます。GDDR6 を使用している場合は、ワイドメモリバスを探してください。

ほとんどのユーザーにとって、計算能力を見るだけで十分です。多くの GPU では、さまざまなタイプのアクセラレーションが提供されています。たとえば、NVIDIA の TensorCore は 5$\times$ によってオペレータのサブセットを加速します。あなたのライブラリがこれをサポートしていることを確認してください。GPU メモリは 4 GB 以上である必要があります (8 GB の方がはるかに優れています)。GUI の表示にも GPU を使用しないようにしてください (代わりに組み込みのグラフィックを使用してください)。避けられない場合は、安全のために2 GBのRAMを追加してください。 

:numref:`fig_flopsvsprice`は、さまざまなGTX 900、GTX 1000、およびRTX 2000シリーズモデルの32ビット浮動小数点計算能力と価格を比較しています。価格はウィキペディアで見つかった推奨価格です。 

![Floating-point compute power and price comparison. ](../img/flopsvsprice.svg)
:label:`fig_flopsvsprice`

私たちは多くのことを見ることができます: 

1. 各シリーズでは、価格と性能はほぼ比例します。Titanモデルは、大量のGPUメモリの利点のためにかなりのプレミアムを要求します。ただし、980 Tiと1080 Tiを比較するとわかるように、新しいモデルの方が費用対効果が高くなります。RTX 2000シリーズでは価格はあまり上がらないようです。しかし、これは、はるかに優れた低精度性能（FP16、INT8、およびINT4）を提供するという事実によるものです。
2. GTX 1000シリーズの性能対コスト比は、900シリーズの約2倍です。
3. RTX 2000シリーズでは、パフォーマンス（GFLOP単位）は価格の*アフィン*関数です。

![Floating-point compute power and energy consumption. ](../img/wattvsprice.svg)
:label:`fig_wattvsprice`

:numref:`fig_wattvsprice`は、エネルギー消費が計算量にほぼ直線的に変化する方法を示しています。第二に、後の世代の方が効率的です。これは、RTX 2000シリーズに対応するグラフと矛盾しているようです。しかし、これはTensorCoresが不釣り合いに多くのエネルギーを引き出す結果です。 

## まとめ

* サーバーを構築する際には、電源、PCIe バスレーン、CPU シングルスレッド速度、および冷却に注意します。
* 可能であれば、最新世代の GPU を購入する必要があります。
* 大規模な展開にはクラウドを使用します。
* 高密度サーバーは、すべての GPU と互換性がない場合があります。購入前に機械仕様と冷却仕様を確認してください。
* 高効率のためには、FP16以下の精度を使用してください。

[Discussions](https://discuss.d2l.ai/t/425)
